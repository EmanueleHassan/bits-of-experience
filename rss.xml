<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bits of Experience</title><link>https://marcohassan.github.io/bits-of-experience/</link><description>A readable view on my studying adventures.</description><atom:link href="https://marcohassan.github.io/bits-of-experience/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:marco.hassan30@gmail.com"&gt;Marco Hassan&lt;/a&gt; </copyright><lastBuildDate>Mon, 22 Jun 2020 17:17:59 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Reinforcement Learning</title><link>https://marcohassan.github.io/bits-of-experience/posts/reinforcement-learning/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;p&gt;
Here are some notes based on the &lt;i&gt;Artificial Intelligence:
Reinforcement Learning in Python&lt;/i&gt; Udemy course.
&lt;/p&gt;

&lt;p&gt;
This are very personal notes that do not intend to substitute the
course. The guy is good. I recommend his courses. I am enjoying and
the way he teaches with minor exercises that makes you well think is
good. 
&lt;/p&gt;

&lt;p&gt;
Note that the code presented is open sourced and can be found &lt;a href="https://github.com/lazyprogrammer/machine_learning_examples/tree/master/rl"&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/reinforcement-learning/"&gt;Read more…&lt;/a&gt; (13 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>https://marcohassan.github.io/bits-of-experience/posts/reinforcement-learning/</guid><pubDate>Mon, 22 Jun 2020 13:25:17 GMT</pubDate></item><item><title>Ein - Ipython Notebooks in Emacs</title><link>https://marcohassan.github.io/bits-of-experience/posts/ein-ipython-notebooks-in-emacs/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;p&gt;
I recently decided to switch from using &lt;code&gt;ob-ipython&lt;/code&gt; to &lt;code&gt;ein&lt;/code&gt; for
working with the ipython kernel on Emacs. I was quite satisfied with
the first but I noticed it was not maintained anymore, while there
seems to be quite a lot of activity around &lt;code&gt;ein&lt;/code&gt;. I therefore decided
to stay up to date in order to benefit from the development in the
second package.
&lt;/p&gt;

&lt;p&gt;
This post summarizes the major things that makes it possible and the
key workflow to operate through &lt;code&gt;EIN&lt;/code&gt; properly.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/ein-ipython-notebooks-in-emacs/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>https://marcohassan.github.io/bits-of-experience/posts/ein-ipython-notebooks-in-emacs/</guid><pubDate>Sun, 21 Jun 2020 19:15:24 GMT</pubDate></item><item><title>HDFS</title><link>https://marcohassan.github.io/bits-of-experience/posts/hdfs/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
After having discussed Object Storage, this posts continues to dig
into the storage layer by briefly introducing HDFS. It will briefly
make the point for the difference between Object Storage and HDFS as a
distributed storage option.
&lt;/p&gt;

&lt;p&gt;
Moreover, it tries to draw a line between Block Storage via Storage
Area Network (SAN), HDFS block storage and the local file system (LFS)
block storage, three topics that highly confused me at first when
writing this posts series.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/hdfs/"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><guid>https://marcohassan.github.io/bits-of-experience/posts/hdfs/</guid><pubDate>Sun, 24 May 2020 15:01:55 GMT</pubDate></item><item><title>Storage Layer - Object Storage</title><link>https://marcohassan.github.io/bits-of-experience/posts/storage-layer-object-storage/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
There are essentially three major storage options. The first being
Block Storage, the second being File Storage and the last being Object
Storage. You can find a good introduction to the three different
options at the &lt;a href="https://www.ibm.com/cloud/learn/block-storage"&gt;following link&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
This post briefly introduces the third storage option above
i.e. object storage.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/storage-layer-object-storage/"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><guid>https://marcohassan.github.io/bits-of-experience/posts/storage-layer-object-storage/</guid><pubDate>Sun, 24 May 2020 13:31:11 GMT</pubDate></item><item><title>Spark Architecture</title><link>https://marcohassan.github.io/bits-of-experience/posts/spark-architecture/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
After the different posts written on setting up a spark session and
working with RDDs &lt;a href="https://marcohassan.github.io/bits-of-experience/categories/spark/"&gt;available here&lt;/a&gt;, this post briefly goes a more into
the detail of the spark physical layer.
&lt;/p&gt;

&lt;p&gt;
It will introduce the concept of DAGs and will make a comparison of
spark and the more restrictive &lt;a href="https://marcohassan.github.io/bits-of-experience/posts/mapreduce/"&gt;MapReduce&lt;/a&gt;. 
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/spark-architecture/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><category>Spark</category><guid>https://marcohassan.github.io/bits-of-experience/posts/spark-architecture/</guid><pubDate>Sun, 24 May 2020 09:44:04 GMT</pubDate></item><item><title>MapReduce</title><link>https://marcohassan.github.io/bits-of-experience/posts/mapreduce/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
This post go briefly over the key idea of using MapReduce as a way to
parallelize operations over multiple distributed machines. 
&lt;/p&gt;

&lt;p&gt;
This was in fact the first tool that was developed for parallelizing
computation over multiple machines and not simply to use multiple
machines for the storage layer.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/mapreduce/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><guid>https://marcohassan.github.io/bits-of-experience/posts/mapreduce/</guid><pubDate>Sat, 23 May 2020 12:25:10 GMT</pubDate></item><item><title>YARN</title><link>https://marcohassan.github.io/bits-of-experience/posts/yarn/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
This post briefly introduces YARN - &lt;b&gt;Yet Another Resource Negotiator&lt;/b&gt;.
It was introduced to overcome the limits of MapReduce v 1.0,
especially the idle resources component, &lt;a href="https://marcohassan.github.io/bits-of-experience/posts/mapreduce/"&gt;discussed in the previous post&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/yarn/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><guid>https://marcohassan.github.io/bits-of-experience/posts/yarn/</guid><pubDate>Sat, 23 May 2020 12:21:55 GMT</pubDate></item><item><title>NLP text classification</title><link>https://marcohassan.github.io/bits-of-experience/posts/nlp-text-classification/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
This post briefly introduce two key concepts for representing NLP
text data. The first is simply based on some frequency metric given a
text corpus, the second &lt;code&gt;word2vec&lt;/code&gt; tries a more elegant and elaborate
approach by trying to extract the semantical representation of words
in a low dimensional space.
&lt;/p&gt;

&lt;p&gt;
Both will be briefly explained. 
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/nlp-text-classification/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>https://marcohassan.github.io/bits-of-experience/posts/nlp-text-classification/</guid><pubDate>Wed, 20 May 2020 20:22:37 GMT</pubDate></item><item><title>Slovak Learning</title><link>https://marcohassan.github.io/bits-of-experience/posts/slovak-learning/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;

&lt;p&gt;
Ok. This post is likely not interesting for any visitor. I am learning
the language and after a discussion with my girlfriend it turned out I
rather write down the new vocabulary for learning the language the
fastest.
&lt;/p&gt;

&lt;p&gt;
In this post I write down my progress and I can go back to it at later
stages.
&lt;/p&gt;


&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/slovak-learning/"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Slovak</category><guid>https://marcohassan.github.io/bits-of-experience/posts/slovak-learning/</guid><pubDate>Sat, 16 May 2020 07:45:34 GMT</pubDate></item><item><title>RDDs Transformations and Actions</title><link>https://marcohassan.github.io/bits-of-experience/posts/rdds-transformations-and-actions/</link><dc:creator>Marco Hassan</dc:creator><description>&lt;div&gt;&lt;br&gt;
&lt;br&gt;


&lt;p&gt;
This post continues the discussion started a few times ago on &lt;a href="https://marcohassan.github.io/bits-of-experience/posts/spark-session-initalization/"&gt;RDD and
Spark&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
I will try to go here in the lifecycle of an RDD and will present the
major Transformation and Actions functions. I will moreover touch on
the physical implementation of Spark as this will give you the mental
tools to properly understand how to properly structure your Spark
workflow in order to optimize the performance.   
&lt;/p&gt;

&lt;p&gt;&lt;a href="https://marcohassan.github.io/bits-of-experience/posts/rdds-transformations-and-actions/"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>Big Data</category><category>Spark</category><guid>https://marcohassan.github.io/bits-of-experience/posts/rdds-transformations-and-actions/</guid><pubDate>Sun, 03 May 2020 13:51:24 GMT</pubDate></item></channel></rss>