#+BEGIN_COMMENT
.. title: Docker
.. slug: Docker
.. date: 2019-09-02 18:21:43 UTC+02:00
.. tags: IT Architecture, Container Management
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT

#+BEGIN_EXPORT html
<br>
<br>
#+END_EXPORT

/Disclaimer; very much of the material under this page is directly copied from various sources on the internet. Check at the Literature section below to get to the source of the post./

The basic idea of Docker is to allow the possibility to save all of
the configuration of an application in one single image. This should
be considered as a safe environment that once properly set up can be
easily shared among different teams and once images are instantiated
all of the different teams can be sure to operate and leverage the
right configuration for running their application.

A simple and straight forward overview about the advantage of Docker
might be found in this sense at [[https://www.tutorialspoint.com/docker/docker_architecture.htm][docker architecture]].

To sum up before starting the basic idea is to create images and to
create containers based on that, which will run then the application
as defined in the docker image.

{{{TEASER_END}}}

** General theory

Lifecycle: build, ship, run. -> build ur application. Wrap it up in a
container and ship it. Run it and scale it then. This allows portability. 

Parts of docker:

*** Image 

Read only. It is a snapshot of a container stored on a registry. U use it as a template for creating containers.

*** Container

This is the runtime instance of the image. A running copy of that.

*** Registry

This is essentially a repository where docker images are stored.

*** Docker Engine

This effectively run the containers. 

*** Difference with VM

With virtual machine you leverage hypervisors that runs virtual
machines. It is what virtualizes resources and makes them sharable.
Up on the virtualized resources you build then your different OS and
specify all of the middleware necessary to run your application.

In contrast to /virtual machines/ that with docker, u have a single
host OS. Notice moreover that docker does not require the entire Linux
OS but rather simply its kernel. Important is moreover to notice that
all the containers share the linux kernel here.

Docker tries to share resources. This means that if a layer is already
running for an application a second application will leverage the
instance of this exact lower layer and will ultimately save resources.




** Create Images with Dockerfiles

*** General Workflow

 The first thing to do is to create your working directory. Don't use
 the root directory as it will expose your container to security
 vulnerabilities.

 Within that directory create then the =Dockerfile= that will include
 all of the set of instructions necessary to create your image.
 Important is that in the Dockerfile each instruction is executed in
 order. So consider that carefully when specifying the commands. 

 You can comment dockerfiles with the comments by =#=.

 Finally use the ~docker build~ command to create the image.

*** Commands for Dockerfile image

 Writing a Dockerfile is the first step to containerizing an
 application. You can think of these Dockerfile commands as a
 step-by-step recipe on how to build up our image. This one takes the
 following steps:

 #+BEGIN_EXAMPLE
## Example of a Dockerfile

FROM node:6.11.5    

WORKDIR /usr/src/app
COPY package.json .
RUN npm install    
COPY . .

CMD [ "npm", "start" ]  

 #+END_EXAMPLE

 Notice;

 - =FROM= start the pre-existing docker image =node:6.11.5=. This was
   cloned from the git repo used in the tutorial. It gives a grasp on
   the layered structure of docker, where you can start in the lower
   layer with basic images and run on top of them new images leveraging
   the basic ones.

 - =WORKDIR= specifies that all the subsequent actions should be taken
   from the directory =/usr/src/app/= in your *image filesystem*.

 - =COPY= the file =package.json= from your docker host to the present
   location =.= such that it is available in the image and the
   deployment can leverage it. Notice that the files passed with the
   =COPY= command will be used by the ~$ docker build~ command to
   create an image. To increase the build’s performance, exclude files
   and directories by adding a =.dockerignore=.

 - =RUN= the command =npm install= inside your *image filesystem*. This
   in general executes commands.

 - =COPY= the rest of your app's source code from your host to your
   image filesystem. I.e. it allows you to copy files from your host
   filesystem to your image filesystem.

The final line with the =CMD= directive is the docker specific way of
specifying some metadata in our image that describes how to run a
container based off of the specified image.

In this case, it’s saying that the containerized process that this
image is meant to support is =npm start=.

Important that the =CMD= commands will run in relation to the image
entrypoint which is discussed here below. If you do not specify any
entrypoint the default is the ~/bin/sh -c~ and therefore you can run
standard bash commands as above.

 Further instructions are:

 - =LABEL= this is metadata. it is a key-value pair that can be used
   later for filtering the containers.

 - =MAINTAINER= also metadata where you can for instance enter the
   e-mail of the maintainer.

 - =EXPOSE= it specifies the port used for the process running on the
   container. 

 - =ENV= it is specifying environment variables. 

 - =ADD= it adds files from remote places to your container.
   an example for it might be ~ADD http:/link/of/picture /tmp~. Notice
   that add has the capability of *untar* files while the =COPY=
   command does not offer that capability. 

 - =USER= it will allow you to specify the user through which the
   commands specified in the =Dockefile= will be run. Recall commands
   are sequential in docker. 

 - =ENTRYPOINT= specifies the entrypoint of the container. the default
   is ~/bin/sh -c~

 You can see that /these are much the same steps you might have taken to
 set up and install your app on your host/ - but capturing these as a
 Dockerfile allows us to do the same thing inside a portable, isolated
 Docker image.

** Image Layering

Notice that each time you =RUN= a Dockerfile it will create a further
layer. If the image has too many layers the image will rapidly grow in
size and you would obtain a very big and heavy image which is not the
goal of Docker.

In order to reduce the layers of an image it makes therefore sense to
leverage the ~&&~ bash command to sequentially execute two bash
commands in one =RUN= instruction such that you will keep your image
lightweight. You can use the split line ~\~ to increase readability.

** Docker images Management

Below a short list of commands. This is however just a way to write
them down one time and start to memorize it. A convenient approach
when looking forward to do smth is to leverage =docker --help= and
search for the keyword of interest. You can then further inspect with
=docker <command> --help=.

#+BEGIN_SRC sh
  # To build an image from a Dockerfile and a context. The build’s
  # context is the set of files at a specified location PATH or URL (git
  # repository location).

  # if the dockerfile is not in the same repo as your context then.
	$ docker build -f <dockerfile> .
  # else; if you are in your context repo and there is where the dockerfile is specified
	$ docker build .

  # to build an image and associate it with a given tag you can leverage the -t flag
	$ docker build -t bullet_inboard:1.0 <directory where the dockerfile is>

  # To list all the avaialble images
  $ docker image ls

  # To run a container:
  $ docker run <img name>

  # Notice that there are multiple useful flags that further 
  $ docker container run --publish 8000:8080 --detach --name bb bulletinboard:1.0
     ## --publich specifies the <host port>:<docker port> for
      # communication. This assures that you can communicate with your
      # docker container through port 8000 of your docker host. For
      # instance it is then possible to look at your application in a
      # browser of the host at localhost:8000.
    ## --detach ask docker to run the container in the background
    ## --name allows to specify a name (here bb) to access the container as this at a later stage.


  # To list all of the containers running:
  $ docker ps

  # To list all of the containers on the system:
  $ docker ps -a

  # To see top processes within a running container:
  $ docker top <Container ID>

  # To stop a running container:
  $ docker stop <Container ID>

  # To remove container:
  $ docker rm <Container ID>

  # To see stats about disk usage, cpu etc of a running container:
  $ docker stats <Container ID>

  # To pause processes running on container:
  $ docker pause <Container ID>

  # To resume after the pause
  $ docker unpause <Container ID>

  # To kill procsses
  $ docker kill <Container ID>

  # To stop the docker deamon running in the background 
  $ servce docker stop
#+END_SRC


* Literature

[[https://docs.docker.com/get-started/]]

https://docs.docker.com/engine/reference/builder/
