#+BEGIN_COMMENT
.. title: Bayesian Networks
.. slug: bayesian-networks
.. date: 2021-02-15 11:23:13 UTC+01:00
.. tags: Bayesian Networks
.. category: 
.. link: 
.. description: 
.. type: text
.. has_math: yes
.. status: public
#+END_COMMENT

#+begin_export html
<style>
img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}
</style>
#+end_export


Here are some Notes about the topic of my Master Thesis - Bayesian
Networks.

Note that most of these Notes are based on /Probabilistic Graphical
Models - Principles and Techniques/ ([[https://www.amazon.de/Probabilistic-Graphical-Models-Principles-Computation/dp/0262013193][Koller and Friedman]]).

{{{TEASER_END}}}


* Bayesian Networks
  :LOGBOOK:
  CLOCK: [2021-02-15 Mon 14:27]--[2021-02-15 Mon 14:52] =>  0:25
  CLOCK: [2021-02-15 Mon 12:50]--[2021-02-15 Mon 13:15] =>  0:25
  CLOCK: [2021-02-15 Mon 11:27]--[2021-02-15 Mon 11:52] =>  0:25
  :END:
  
The general outlook.

So recall that in general you have three elements in Bayesian
Networks:

- Representation

  - how do you represent the joint probability of the events as a
    network (i.e. as a graph data structure)? Can such structure
    represent the joint in a compact way due to the conditional
    independence relations?

    *Note 1:* that such compact formulation is one of the key benefits of
    Bayesian Networks as it really gives the possibility of shrinking
    the amount of parameters needed to describe the full joint
    probability leveraging the independence structure among the RVs.

    *Note 2:* this formulation is /transparent/, i.e. highly
    understandable also to non-AI experts. It is so to say highly
    explainable and in this new buzz of /explainable AI/ a solid
    option.
  
- Inference

  - given some information about some Parent variables, how can I
    infer/compute the distribution of the children in the Network?
  
- Learning

  - given some observed data, how can I use such information to
    construct / (infer) / learn the  /structure/ of the network?

  - given some observed data, how can I learn the /parameters/ of the
    network? I.e. how can I use the information content of the data to
    derive some plausible parameterization of the network.


So these are the main tasks you have to deal with in Bayesian
Networks. Basically you can do all of the three in a very simple way,
which is from a theoretical standpoint very concrete and
straightforward or you can start to consider all the aspects of the
problem going quickly towards more complex situations.

** Representation

   #+BEGIN_EXPORT html
   <br>
   <br>
   #+END_EXPORT

   #+begin_src plantuml :file ~/Desktop/Blog/images/bayesNet1.svg :exports none
   @startuml
   circle A
   circle B
   circle C
   circle D


   A --> B
   A --> C

   B --> D
   C --> D
   @enduml
   #+end_src

   #+RESULTS:
   [[file:~/Desktop/Blog/images/bayesNet1.svg]]

   #+begin_export html
<style>
.bg-svg {
  width: 40%;
  background-image: url(../../images/bayesNet1.svg);
  background-size: cover;
  height: 0;
  padding: 0; /* reset */
  padding-bottom: 92%;
  border: thin dotted darkgrey;
  float:right;
  margin-left: 5%;
}
.content p{
    display: block;
    margin: 2px 0 0 0;
}
</style>

<div style="width: 100%">
   <div style= "width: 70%; margin-left = 5%;">
      <div class="bg-svg">
   </div>
   <p>

   <br/>
   <br/>

   As mentioned bayesian networks allow us to express the joint
   through less parameters.

   <br/>
   <br/>

   The idea is that you factorize the joint as a product of the
   conditionals and given the parameterization of the conditionals you
   fully specify the joint. Given the independence structures the
   number of factorization of conditional terms is limited and the
   overall necessary parameters to specify the joint small.

   <br/>
   <br/>
   
   For instance if a Variable D is fully determined by its parents B,
   C in this graph:

   <br/>   
   <br/>
   
   Then you might well understand that given B, C you do not need
   P(D | A, B, C) parameters as P(D | B, C) suffices.
  </p>
  <br style="clear: both;" />
</div>
    #+end_export

   #+BEGIN_EXPORT html
   <br>
   <br>
   <br>
   <br>   
   #+END_EXPORT
    
   A concrete example is the following:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-15_um_13.21.25.png">
#+end_export

   Notice there that instead of needing 2 (Diff) * 2 (Int) * 3
   (Grade) * 2 (Sat) * 2 (Let) = 48 parameters to describe the joint
   you simply need 2 + 2 + 12 + 6 = 22.

   Given this understanding it is immediate to see that Bayesian
   Networks are defined as above, i.e. as a graph data structure to
   which /local probabilities/ are applied. In the specific each RV in
   the graph is associated with /conditional probability distributions
   (CPD)/ that specify the distribution given each possible joint
   assignment of values to its parents. And the graph structure
   together with the CPD specifies the Bayesian Network.

   A *second* representation/ definition of Bayesian Networks is to
   define it via a /global probability P/ together with the independence
   relations determined by the graph.

   To determine independence relations in graphs you can use standard
   logic where the argument is essentially the following:

   #+begin_quote
    Our intuition tells us that the parents of a variable “shield” it
    from probabilistic influence that is causal in nature. In other
    words, once I know the value of the parents, no information
    relating directly or indirectly to its parents or other ancestors
    can influence my beliefs about it. However, information about its
    descendants can change my beliefs about it, via an evidential
    reasoning process. (Koller and Friedman)
   #+end_quote

   Such that you would have the following /local independence
   structures/:

   $$ For each variable X_i : (X_i \perp NonDescendants X_i | Parents
   X_i) $$

   Notice that such set of independence is called an I-map for a
   probability distribution /P/. You then say that a graph /G/ is an
   I-map for /P/ if it satisfies the I-map relations specified /I(P)/.

   And you would ultimately have the following definition:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-15_um_14.50.38.png">
#+end_export

   So that you basically take here the opposite direction, from a
   joint distribution /P/ and the local independence structure you
   have a fully specified Bayesian Network.

   *Note* that you can go from one representation to the other and the
   BN is defined *if and only if* you can from one to the other.

*** On Graph Dependencies and D-separation

    Given the above discussion and the fact that it is possible to
    determine the BN given a joint density and a Graph structure, the
    question now is on how to extract the conditional independence
    structures implied by a graph, i.e. to extract the I-map
    relations.

    In order to do that a simple algorithm exists the /d-separation
    algorithm/.

    The idea here is the following. You know that for three nodes X,
    Y, Z there exists a dependence structure between X and Y if one of
    the following conditions *hold*:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-15_um_15.18.31.png">
#+end_export

     This is quite intuitive.

     It follows now that we can quickly assess whether two variables
     are generally conditionally independent by making reasonings
     leveraging the active trails as above.

     I.e. for two variables to be *dependent* there must be an active
     trail as defined by the conditions above.

     Notice that for instance in the student BN you can investigate
     the conditional independence between SAT and Difficulty as
     follows:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-15_um_15.25.30.png">
#+end_export


     Generally it holds:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-15_um_15.26.42.png">
#+end_export

     You can then find in the book an algorithm for checking
     d-separation, if interested at any point in time. Notice that
     there is are also reasonings about /completeness/ and /soundness/
     of d-separation. I.e. how well that covers and fully specifies
     independence structures of /P/.

     I write in here the definition of /completeness/ and /soundness/
     should it be of interest at any point at a later stage:

     /Soundness/:

     If two nodes X and Y are d-separated given some Z, then we are
     guaranteed that they are, conditionally independent given Z.

     /Completeness/:

     D-separation is complete if it detects all of the possible
     independencies. I.e. if two variables X and Y are independent
     given Z, then they are d-separated.

     Formally:

#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-19_um_09.32.33.png">
#+end_export

*** On CPD

    So far we discussed the possibility of representing the
    high-dimensional joint distribution into a product of
    lower-dimensional CPDs or factors, i.e. a product of local
    probabilities models.

    In this section we explore more into the detail the possibility of
    representing such CPDs.

    
**** Tabular CPD

     This is the most basics form of CPD. It works for spaces composed
     solely of *discrete* valued RV.

     It consists in expressing the $P(X | PA_X)$ as a table that
     contains the joint probability of $X \and PA_X$.

     This is essentially what was given in the example above.

     *Note:* it is important to realize that the number of joint
     probabilities that you have to express is given by

     $$|Val(PA_X)| * |Val(X)|$$

     I.e. it grows /exponentially/ in the number of parents. This is a
     serious problem in many settings. You can also not ask an expert
     to express all such CPDs. He will loose patient at some point.

     So the idea is to find a mechanism to express each and every
     $P(X | PA_X)$ for each X and $PA_X$ but without doing the
     exercise explicitly.

     I.e. you should find a /functional formula CPD = f(X, PA_X)/ such
     that you can leverage some structures represented by the
     functional formula and do not have to express all of the
     probabilities individually.

     You can then read in the book some forms of such deterministic
     CPDs. The general idea is quite simple. There might be
     deterministic structures that naturally arise due to the
     structure of the modeled phenomena.

     Moreover for deterministic networks you might have the notion of
     =context specific independence=. Here the idea is that given some
     particular configuration $X \cup Y \cup Z$ you might have
     independence of X and Y given Z in this particular configuration.

     
**** Context Specific CPDs for non-deterministic dependecies

     Structure in CPDs might not just arise in the case of
     context-specific CPDs.

     The idea is that often there is some structure such that for
     certain realizations a RV X given some partial assignment to some
     subset of parents $ U \subset PA_X$ the probability is fully
     specified and does not depend on the remaining parents.

     Two ways to capture such structure is through Tree-CPDs and
     rule-based CPDs.

***** Tree-CPDs

      This is a very intuitive structure for every human. In fact
      trees are used continuously. There is a natural tendencies for
      such structures in engineering so nothing new. You saw them 100s
      time.

      However, what is interesting is the example. In fact it is easy
      to see that by leveraging the tree structure, i.e. the context
      specific structure and the resulting independencies you can
      highly reduce the total number of parameters.

      To understand that think of the following example:

      #+begin_export html
       <img src="../../images/Bildschirmfoto_2021-02-19_um_12.01.18.png" class="center">
      #+end_export

      It is immediate then to see that the above highly reduces the
      number of parameters.

      #+begin_export html
       <img src="../../images/Bildschirmfoto_2021-02-19_um_12.03.41.png" class="center">
      #+end_export


      Notice that when we talk we say that the Tree-CPDs represent the
      network context specific information. This is immediate to see
      as you do not in fact consider the full structure of the network, but
      you already factor out some of the independencies.

      To see that consider, the following case where you would have
      two recommendation letters and are applying for a job. You have
      to choose among the two. Then you can represent the case in the
      following ways:

      #+begin_export html
       <img src="../../images/Bildschirmfoto_2021-02-20_um_19.08.25.png" class="center">
      #+end_export

      It is clear that on the left you work at the network structure
      not leveraging context specific information while on (b) you
      already start to pack that in.

***** Rule-based

      Another possibility to pack information of the network structure
      by leveraging context specific information is via =rule-CPDs=.

      They are defined in the following way:
      
#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-20_um_19.31.28.png" class="center">
#+end_export


#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-20_um_19.50.22.png" class="center">
#+end_export

      It follows immediately that it basically consists in sets joint
      co-occurrences of RV and assigns probabilities to such cases.

      With it you can then basically express all sorts of CPDs
      structures that are based on some partitioning.

      It is in fact immediate to see that tree-CPDs can be easily
      expressed via rule-based CPDs but the converse is not true.      

**** Independence of Causal Influence

     Here the idea is the case where you have a set of variables X_i
     influencing Y, such that X_i can influence Y in an arbitrary
     way. I.e. you assume that X_i can interact with each other in
     complex ways making the *effect of each combination unrelated to
     any other possible combination*.

     Two such models that fulfill such characteristics are

      - the noisy-or model

      - the generalized linear models.

***** Noisy Or Model

      This is a very simple model. If an event occurs then you have no
      100% guarantee that the usual reaction will occur. That is there
      is some noise in the model and some side reaction might happen.

      Think for instance at working hard at work. Then with 90% you
      might have a successful project. However, due to some random
      factor, say sudden cut of budget or company restructuring, your
      project might fail. This is the /noisy part/ and the noisy or
      model.

      This is the general setting. It is then possible to express such
      a noisy model through a graphical representation.

      Think of the following:

   #+begin_src plantuml :file ~/Desktop/Blog/images/bayesNet2.png :exports none
   @startuml
   circle W
   circle W_1
   circle S

   W -right-> W_1
   W_1 -right-> S
   @enduml
   #+end_src

   #+RESULTS:
   [[file:~/Desktop/Blog/images/bayesNet2.png]]

#+begin_export html
 <img src="../../images/bayesNet2.png">
#+end_export

      It follows then that W_1 expresses the probability of the noisy
      factor taking place - i.e. budget restriction. Such that
      \lambda_W = P(W_1 | W) = 0.9. Where W = work hard and W_1 = normal condition.
      Notice now, the case where independently on your hard work the
      team mate hard work also affects the result. Then you could be
      in a situation as the following
      

   #+begin_src plantuml :file ~/Desktop/Blog/images/bayesNet3.png :exports none
   @startuml
   circle W
   circle W_1
   circle TW
   circle TW_1

   circle S

   W --> W_1
   TW --> TW_1
   W_1 --> S
   TW_1 --> S
   @enduml
   #+end_src

   #+RESULTS:

#+begin_export html
<div  style ="height: 40%; width: 50%; margin:0 auto;">
   <img src="../../images/bayesNet3.png">
</div>
#+end_export

      Again also the TW hard work induces a probability of success of
      95%, i.e. \lambda__TW = P(TW_1 | TW) = 95%, and there is a 5%
      prob of failure due to restructuring and budget cut.

      This is essentially the Noisy-or model. You have a deterministic
      or relation influencing the project success - i.e. either your
      work or your team members work. You have noise, i.e. despite the
      factors you might have project failures due to some
      unpredictable conditions - noise. Overall the probability of
      success is given by products of lambdas. I.e. if both team work
      and individual work multiply both lambdas. If just one, then
      take the respective lambda etc.

      More formally such model is defined as:
      
#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-21_um_09.48.03.png" class="center">
#+end_export

      Notice that the /leak probability/ was not discussed that
      far. It consists of the probability of project success even in
      the case that no hard work - for neither myself nor the team
      members was put in the project.

      *Note* that in such a models the parameters would be represented
      by the estimation of the /different lambdas/.

***** Generalized Linear Models

      These are networks where the interaction among the variables is
      represented by generalized linear models you saw a couple of
      times in your studies.

      Recall that in generalized linear models you would have a linear
      model

      $$ f(X_1, ..., X_p) = \sum_{i}^{p} w_i * X_i  $$

      That would represent the load that the parents sets on the
      system. Where the load of each individual variable might be
      higher or lower and is therefore weighted.

      Then basically you would transform such a load into a
      probability by applying a sensible transformation that could
      well reflect the system work. I.e. a very wide used example is
      the S-shaped structure that can be modeled via logit or probit
      models.

      You can also start to make inference on what happens
      if... cases. For instance in the book it is discussed on how, in
      the case of a binary model, the log-odd probability changes
      w.r.t. a change in one of the independent binary RV. This gives
      you an idea of some possible structures and relations that could
      occur in such models so that if representative of some real
      world situation you can leverage on this.

      *Note* that here once the transformation is defined the only
      parameters left are the weights/loads entering the linear part
      of the model. You should therefore specify these under this
      setting.

      
**** Continuous Variables

     These are not discussed here. Have to move on. The idea is always
     the same. You now have some continuous variables, say Y and
     X. You would then have for instance a relation governed by a
     normal distribution where $Y \sim N( \beta * X, \sigma^2)$.

     That would actually be the case when

     $$ Y = \beta_0 + \sum_{i = 1}^{P} \beta_i X_i + \epsilon $$

     where \epsilon is gaussian N(0, \sigma^2). So again the usual
     stuff.

**** Hybrid Models

     Here the basic idea is that you have a network where you have a
     mixture of continuous and discrete variables affecting other
     variables.

     Then one possibility to model such hybrid situation is the
     following

     
#+begin_export html
 <img src="../../images/Bildschirmfoto_2021-02-21_um_10.34.49.png" class="center">
#+end_export

    Notice that such CLG model induces a mixture on the continuous
    parents Y. Moreover it does not allow to have /discrete
    children/. Notice moreover that the number of parameters here is
    exponential in the number of discrete variables.

    Another possibility to model hybrid models is via threshold
    models, where you would easily go from continuous parents to
    discrete children.

    Notice that these are just very basic possibilities and the idea -
    both here and in the book I guess - is to start to make you reason
    about how to model such situations. The possibilities are however
    uncountable and therefore it is up to you then on a project to
    spend some time at the beginning to engineer the entire model and
    decide on the setting.

    

                
** Inference

   An important exercise for inference is to query
   distributions. I.e. as said the task is to compute the probability
   of the occurrence of some RV given some evidence /E/, i.e. a subset
   of RVs that is observed.

   So in general the task is to determine:

   $$ P (Y | E = e) $$

   where =Y = query variable= and =E = evidence=.

   Given such definition of probability queries it is possible to
   introduce the *first type* of query: /MAP queries/.

   $$ MAP (W| e) = \operatorname*{argmax}_w P (w,e)$$

   where W = all non-observed RV.

   #+begin_quote
   I.e. in MAP queries you are interested in finding the most likely
   joint assignment of the non-observed variables given the evidence.

   If you perform MAP queries for a single RV Y then you are basically
   computing a probability query for all of the possible realizations
   y and selecting the most probable one.

   Notice that the joint prob. maximizing the likelihood might well
   differ from the individual RV maximizing realization.
   #+end_quote


   A *second type of query* is: /Marginal MAP Query/:

   The idea of this is well explained in the book via example.

   Imagine you have a class of disease. You want to find the most
   likely disease given your evidence. Assume that you observe a
   subset of symptoms E = e. You want to find the MAP assignment of
   the disease Y.

   The issue is now that you have non-observed symptoms: Z.

   If you now have a disease that has just a small number of
   associated symptoms with high probability, and you observe such
   symptoms, then your MAP query will likely select this realization
   as most likely.

   In reality there might well be a more likely realization - i.e. a
   different RV that is associated with a lot of symptoms with small
   probability. The result is that when taking that into account and
   therefore considering the possible influence of non-observed
   symptoms the conclusion might be well different.

   For this it makes sense to consider /marginal MAP/ that tries in
   fact to adjust for the presence of the other *non-observed RVs
   influencing the outcome*.

   $$ marginal MAP (Y | e) = \operatorname*{argmax}_Y  \sum_{Z}{P (Y,
   Z | e)} $$

   

