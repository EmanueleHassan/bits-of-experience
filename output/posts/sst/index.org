#+BEGIN_COMMENT
.. title: SST
.. slug: sst
.. date: 2022-03-30 17:38:15 UTC+02:00
.. tags: finance
.. category: 
.. link: 
.. description: 
.. type: text
.. has_math: yes
#+END_COMMENT

#+begin_export html
<style>

img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}

.container {
  position: relative;
  left: 15%;
  margin-top: 60px;
  margin-bottom: 60px;
  width: 70%;
  overflow: hidden;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
  display:block;
  overflow-y: hidden;
}

.responsive-iframe {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
  width: 100%;
  height: 100%;
  border: none;
  display:block;
  overflow-y: hidden;
}
</style>
 #+end_export

So time to learn a bit of SST and the concepts in this dimension.

As I am running the thing it will make sense to have a broad
understanding of the thing.

It will give as well an understanding of some terms that you see going
around.

{{{TEASER_END}}}

It will give you some conceptual understanding of some inputs that are
feeded into the system. It will give a bit of understand on how
certain things run.

Some concepts as RBC are tighlty related to it etc.

So basically I gathered a bit of sources:

- [[https://www.finma.ch/FinmaArchiv/bpv/download/e/WhitePaperSST_en.pdf][whitepaper of FINMA]]

- [[http://www.actuaries.org/CTTEES_SOLV/documents/Stockholm_Keller.pdf][more compressed info]]

- [[https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjOpcOI8vT2AhUIuaQKHcZEBHMQFnoECAMQAQ&url=https%3A%2F%2Fwww.ag-ai.nl%2Fdownload%2F1378-12-4PP-summary_swiss_solvency.pdf&usg=AOvVaw2z6AoKfDr7WpGF_PoPx-iZ][more compressed info in plain text]].

Now the task is simply to put the info together but before a clear
high level understanding about SST.

That is regulatory capital. You also have to make some Solvency II
calculations but leave it on the side for now as you can eat simple
one piece of the cake at the time.

Understand in any case the difference of EC and RC.

   #+begin_export html
   <div class="container"> 
     <iframe class="responsive-iframe" src="https://www.youtube.com/embed/l8lrpWp6MJs" frameborder="0" allowfullscreen;> </iframe>
   </div>
   #+end_export

At the end you can simply take it as two different constraints that
you as a business have to fulfill. It is a simple:

#+BEGIN_src latex :results drawer :exports results
\[ Capital that will impose your constrains = max (RC, EC)  \]
#+END_src

#+RESULTS:
:RESULTS:
\[ CapitalToSetAside = max (RC, EC)  \]
:END:

I guess that here comes the science in the investment part as well.

When you invest you have to think about how a thing impacts the
both. This is why you make the optimization at group level and then
you propagate and implement. 

{{{TEASER_END}}}

* Motivation and origin of SST

  The financial stability of several insurers has been shaken in the
  past few years. Events which have had significant adverse effects
  include the /crash in the equity markets/ in 2001 and 2002, the steady
  fall in bond yields as well as the impact of increased longevity.

  For some insurers, the effects of the fall in the equity markets
  have been compounded by deteriorating technical results and large
  catastrophe claims.

  This is actually what happened in the Swiss insurance market back in
  2001 and why everything crashed drammatically.

  You can get an idea by reading the [[https://www.swissre.com/dam/jcr:638f00a0-71b9-4d8e-a960-dddaf9ba57cb/150_history_of_insurance.pdf][following paper]]:

  #+begin_quote
The size and complexity of losses would force companies but also
society at large to think differently about risk. Although the stock
markets remained reasonably robust in the aftermath of 9/11, the
attack brought the global economy to a grinding halt, due to
uncertainty of the effect on stocks worldwide. 

Insurers had to contend with unstable financial markets during this
volatile period

The insurance industry shouldered much of the economic
burden. Insurers paid an estimated USD 23.8 billion, making 9/11 the
most costly insured man-made disaster ever – and, at the time, the
second most expensive insured loss after Hurricane Andrew. 

Assessing the insured loss was a highly complex undertaking; large
claims were filed for a number of seemingly unrelated risks including
aviation, property, liability lines, business interruption and life
insurance. Losses and potential exposures were not confined to New
York, either – airlines were grounded, restrictive security measures
were implemented and events were cancelled around the world.

Some insurers, and European reinsurers in particular, embarked on an
accelerated programme to strengthen their risk management, governance,
and asset management. They fortified their systems to manage
accumulations of risk and liabilities in their asset portfolios and
developed the first economic models.
  #+end_quote 

  So basically this is what brought to a change in the regulation
  environment for the insurance sector.

  The result was:

  #+begin_quote
While there are many strands to these changes, they all have common
themes: more appropriate assessment of the specific risks companies
are running using an improved and comprehensive financial reporting
framework, standardization of approaches between countries and
industries where sensible, and improved transparency and
comparability.
  #+end_quote
  

* SST Core Principle

  #+begin_quote
The proposal, which is described in more detail in later sections of
this document, can be summarized as protecting insurance customers by
ensuring that each insurance company has sufficient capital available.

‘Sufficient’ means that even in an unlikely situation (e.g.  one with
a probability of 1%), there is (on average) enough capital to allow
the assets and liabilities of the company to be transferred to a third
party. There must then still be sufficient assets to cover the
liability and the future capital costs of that third party.
#+end_quote
  

* On SST and Solvency II

  In order for Swiss companies not to be at a competitive disadvantage
  to insurers domiciled in EU (and EEA) member countries, it is an aim
  of the SST to be compatible with the future European Solvency II
  framework.

  This entails in particular that both a minimal solvency level and
  target capital have to be calculated and that internal models –
  provided they satisfy regulatory requirements - can be used for
  target capital calculation.


* Consistent Valuation of Assets and Liabilities

  This risk-based supervision aims to take all financial and insurance
  risks into account, especially asset and liability risks. The system
  will focus on explicitly measuring risks and minimizing systemic
  risk via transparency.

  This is in fact the first requisit for a transparent and comparable
  regime:

  #+begin_quote
  assets and liabilities must be valued in a consistent way by each
  company.
  #+end_quote

  This leads to the concept of *economic vs. accounting
  information*. So you see that is worth reading such papers. You are
  finally able to put all of these concepts flying around in your data
  into a coherent frame.

  The necessity for the translation is that:

  #+begin_quote
Companies, investors and regulators have long struggled with
interpreting accounting information where assets and liabilities are
valued on different bases.

The inconsistencies can cause artificial volatility in free capital.
  #+end_quote 

  So SST aims to bring a little bit of order in this sense:

  #+begin_quote
  The SST is based on “market-consistent valuation” of both assets and
  liabilities. This is described in more detail in later sections, but
  essentially it means that assets are valued at their price in the
  market, while guaranteed liabilities are valued based on the price
  that financial markets would place on these liabilities, taking into
  account all embedded options and financial guarantees.
  #+end_quote

** On Internal vs. Standard Models

   Since risk profiles of the supervised insurers can be very
   heterogeneous, a regulatory model capturing correctly the risk
   situation of each company would be very complex.

   For the SST, simpler models were developed which have to be adapted
   by each company to fit its specific risk profile, thereby also
   making companies responsible for target capital calculation.

   While a standard model is being developed to ensure that all
   companies can implement a minimum standard, the SST encourages
   companies to develop internal models.

   #+begin_quote
   Companies can deviate from the standard models, parameters
   etc. with the permission of the regulator.

   This permission is granted if a company can show that its internal
   model better reflects the risk situation than the standard model.
   #+end_quote

** On the capital concepts at the basis of SST

   Insurers must calculate two capital numbers: 

   - *minimum solvency* (statutory - i.e. minimal amount of capital
     for an insurance to retain a license to do business).
     
   - *target capital* (market-consistent).

   With minimum solvency and target capital, two complementary views
   of an insurer’s financial situation are incorporated into the SST:
   the statutory and the market-consistent view.

   Minimum solvency is based on the /statutory balance sheet/. It is
   easy to calculate but does not refelct directly the insurer’s
   specific risk exposures.

   Statutory balance sheets are some given accounting standard in
   order to compose your balance sheet. So will not go in the details
   of it but I imagine simply a situation that based on a given
   logic - a business focused - you aggregate your numbers and do the
   accounting. Then based on this you have some dummy calculations in
   order to arrive to the minimum solvency capital - meaning that if
   the numbers do not add up in this dimension *you are basically
   already bust*.

   The target capital, conversely, is /risk-based/ and grounded in a
   *market-consistent assessment*. So you see that here you start to
   depart from the accounting dimension and you start to price the
   stuff at fair value.

   So you see there is no way to escape accounting in the financial
   world. That is the basis as everything is registered in such
   dimensions. It is then annoying cause there are a lot of nuances
   and accounting does not always has to relect the actual as-is
   situation. I remember the many different ways of reporting the
   things in your books that I studied it in my bachelor; the various
   GAAP vs IFRS standards and the many different "views of the world"
   and ways of doing things.

   So basically then this is as well a lot of time the operation in
   this world. The reasoning is pretty much the following: /ok there
   is accounting but we all know that it does not actually capture/
   /the as is value on your books/.
   So make sure that you are actually pricing everything at fair value
   and then based on this fair values start to make your risk
   scenarios.

   At the end you basically have the two following core principles:

   - statutory capital: if you do not meet the minimum - goodbye my
     friend.

   - target capital: make all the fair value conversion and risk based
     calculations. If you do not have enough capital to meet this
     target capital you might be still a running company. But we fear
     that you are not well positioned to cover possible losses and
     face possible risks. Meaning: we are coming down and will start
     to check on you.

   #+begin_export html
    <img src="../../images/Screenshot 2022-04-02 101824.png" class="center">
   #+end_export
   
*** On the geo-component of the thing

    Both minimum solvency and target capital requirements would apply
    to insurers domiciled in Switzerland, together with their
    branches, i.e. on a legal entity level. Excluded are subsidiaries
    or branches of insurers domiciled outside Switzerland.

    So this bit is as well interesting. This is why everything is so
    messy and fragmented in the system.
    
*** On the Market Consistent Valuation

    So you should understand by now the difference between the
    economic and accounting view.

    In this section we talk about market consistent valuation - that
    is a relevant topic for the risk based capital models and the
    economic view so to say.

    The principle is the following:

    #+begin_quote
    Where possible, market-consistent valuation of assets and
    liabilities will be based on observable market prices. If no
    actual market prices are available, market-consistent values will
    be determined by examining comparable market values, taking into
    account liquidity and other product-specific features.
    #+end_quote

    Note now that if it is easy to price the asset side of the balance
    sheet given market conditions it is generally more difficult to
    price liabilities at a market consistent rate.

    Here you will eventually come to the concept of replicating
    portfolios and similars that you see quite often going around in
    the system.

    In any case, given the difficulty of giving a market value to the
    liability side of the balance sheet you generally talk about a
    /Best-estimate/ effort for pricing the libialities in a fair
    value. On the top of it you add some buffer for the [[*Risk Margin][Risk Margin]] -
    meaning the needed capital in order for a private to take over
    your liabilties without having to register a loss on the books.
    
*** Best Estimate of Liabilities

    For liabilities, the market consistent value is defined as the sum
    of the best-estimate of the liabilities and the risk margin.
    
    #+begin_export html
     <img src="../../images/Screenshot 2022-04-03 181454.png" class="center">
    #+end_export

    Note that the risk-bearing capital naming convention is
    clear. Best estimate liabilties do not carry the risk. I.e. they
    cannot absorb risk. It is not buffer. It is claims. 

    Note now the following:

    No specific method for valuing the liabilities on a market
    consistent basis has been prescribed by the regulator. Valid
    approaches include valuing a replicating portfolio (see for
    instance [BH]), modeling all policyholder liabilities and
    interactions with the financial markets on a stochastic basis and
    using discounting methods (deflators) and/or scenarios
    (risk-neutral) which ensure market-consistency.

    So you see that there is an entire science over there. Would be
    cool to read into such methods at some point. You understand what
    your input is now.

    Note now the origin of the best estimate naming convention:

    #+begin_quote
All assumptions concerning insurance risks (e.g. mortality, disability
rate, etc) are to be made on a best-estimate basis /without implicit
or explicit safety margins/.
    #+end_quote


* On the Target Capital calculation

  So understand that SST is interested in the risk of an insurance as
  a whole.

  This means that it is interested in:

  - market risk

  - credit risk

  - life insurance risk

  - non-life insurance risk

  - health insurance risks

  #+begin_export html
   <img src="../../images/Screenshot 2022-04-02 234429.png" class="center">
  #+end_export

  It is clear that you are taking care of the financial risk of your
  company. 

  So understand that the risk modeling is done at two levels:

  - on a stochastic level - i.e. you model you risks in the stochastic
    way. You have your different risk models in order to compute
    possible scenarios etc. You then check at the tails of the
    distributions and all of that stuff where you pretty much
    specialized in your academic life.

  - scenario - these are like single-state shocks that are
    calculated. They should capture possible adverse scenarios that
    are not captured in your parameteric stochastic models. They will
    be then used in order to do adjustments to the risk based capital
    computations coming out of the the stochastic compuations.

  Meaning the final capital requirements will result from some kind
  of aggregation of the two.
  
  #+begin_export html
   <img src="../../images/Screenshot 2022-04-02 104930.png" class="center">
  #+end_export

  Note now that the target capital is basically composed of two
  components:

  - Expected Shortfall

  - Risk margin

  #+begin_export html
   <img src="../../images/Screenshot 2022-04-02 234202.png" class="center">
   #+end_export

   While the conceptual understanding of the expected shortfall is
   very clear from your academic background.

   An understanding of the risk margin is a little bit tricky and it
   is outlined in [[*Risk Margin][Risk Margin]].


** Risk Margin

   The risk margin of an insurance portfolio is defined as the
   hypothetical cost of regulatory capital /necessary to run-off all
   the insurance liabilities/, following financial distress of the
   company.

   For the regulator it is imperative that in the case of insolvency,
   the rightful claimants be protected.

   Policyholders are best served if a third party can take over the
   assets and liabilities of their initial insurer.

   A third party will only be prepared to do this if the cost of
   setting up the regulatory capital that would be required is covered
   by the portfolio.

   This is the obvious statement: If the private sector takes over the
   thing, then the private will just step in if it makes economical
   sense for them.

   It should be noted that the risk margin is only indirectly risk
   bearing and does not belong to the insurer but to the
   policyholders, and is part of the market-consistent liabilities of
   the company. /In case of a transfer of the portfolio, the risk
   margin has to be transferred too/.

   Note now why this risk margine must sit on the top of the ES
   calculation for the company.

   The basic reason is outlined in section 4.3 of the whitepaper and
   is well described into the following image: 

   #+begin_export html
    <img src="../../images/Screenshot 2022-04-03 184837.png" class="center">
   #+end_export

   So the idea is the following:

   Asset allocation can be changed to optimally represent the
   insurance liabilities. This asset allocation is called optimally
   replicating portfolio. If an optimally replicating portfolio is
   achieved, target capital requirements are minimized.

   So I guess that the reasoning is a little bit as well in that
   direction.

   When the third party will take over the stuff it will have a higher
   expected shortfall as it has not reached an optimal asset
   allocation replicating the portfolio. So it is obvious that setting
   apart just the ES stochastic number will not be enough as then when
   bad things happens this transition will be there and you have to
   have capital for making it possible and cover the costs of a
   sub-optimal asset allocation.

   Note that the rate of covergence to the optimally replicating
   portfolio one is a function of the liquidity of your assets etc.

*** Actual calculation

    Update 07/04/2022:
   
    Ok so here it is interesting to check at the different material and
    sources. They are not perfectly aligned.

    I guess that while the closing remarks of the previous sections
    point to a theoretical motivation for the risk margin. The actual
    calculation is not based on that concept.

    It is actually much easier.

    The idea is to say. Another dude in the private sector will take
    over that book and will *run it off*.

    So basically you have to think:

    - how much capital will you need to set aside in order to meet the
      required target capital in time?

    - how much will the target capital be?

    So basically you answer all of these questions in the following
    way.

    You say - it is difficult to estimate the target capital that the
    other dude will need because of the reasoning expressed at the end
    of the previous paragraph. Moreover it is fun cause I am not even
    sure that the other dude will ultimately run off the entire book.

    Maybe he will as per regulatory imposion. Not that interesting to
    me in any case. Take it as given.

    So what you basically say is that:

    - target capital will be prop. to the best-estimate for the
      libabilities.

    Such that once you have an estimate of the run off pattern of the
    liabilities based on how quickly you can sell all of these books
    you can compute your risk margin as follows - with a discounting
    rate /s/ fixed by the regulator, usually 8-10%:
    
    #+begin_export html
     <img src="../../images/Screenshot 2022-04-07 172244.png" class="center">
    #+end_export

    So you see that the ratio - target capital to liabilities is given
    based on the one of today and is assumed to be constant in time.

    
    Note that all of this is again quite arbitrary. Cause it is
    fun. The capital of one year is likely the same of the next year
    so makes little sense to sum it according to my mind. So basically
    the issue mentioned in the other source and expressed in the
    previous section is not accounted for. 

    Anyways you see that this side of the world functions like
    this. At the end you just ask the insurances to put a little bit
    more capital aside. I guess the motivation is the one of the
    previous section.
       

** On the standard models

   I am making some very quick notes here as I guess that in any case
   the internal model will follow similar structures and will more
   less borrow and extend from the standard. I can not imagine a
   complete different model. You will likely not get the approval
   otherwise.

   In the whitepaper there is a brief paragraph about the different
   distributions and assumptions for the stochastic models. That is
   not that interesting to you.

   Interesting is the understanding of the following types of
   parameters:

   - =Type 1=: Parameters which are set by the regulator and which can
     not be changed. For instance, these include the risk-free
     interest rate, the safety level and the probabilities of some of
     the prescribed scenarios as well as some other macro-economic
     parameters. Other examples would include parameters specifying
     the frequency and severity of natural catastrophes. 

   - =Type 2=: Parameters which have to be set by companies, for example
     the volatility of the hedge fund exposure, where the exposures of
     different companies are so different that prescribing any fixed
     parameter would be pointless. 

   - =Type 3=: Parameters which are set by the regulator and which can
     be changed by the companies. Most of the parameters are elements
     of this class. The parameter estimation by the company has to
     follow the guidelines of the regulator. The company has to show
     the estimation procedure to the regulator.

   So you see that in standard models you have usually prescribed
   models and you then just set the parameters. This is the actual way
   smaller companies are working.

   
* Asset Models in the Standard Models

  So note that there is a section in the whitepaper that goes a little
  bit deeper in the different modeling techniques of the standard
  models in order to compute the general risk of insurance companies.

  So generally you have a split in the 5 categories mentioned in the [[*On the Target Capital
 calculation][On the Target Capital calculation]].

  You can read the risks for the other categories in there if you want
  if you will ever have time - I doubt it as I am already quite under
  pressure with my current work.

  This section deals primarily with the asset model as this is the one
  of interest for the market risk compoenent that your team deals
  with.

  Note that the standard model for measuring the asset model risk is
  based on the standard RiskMetrics technique - conceptually similar I
  read in the paper.

  I understand by now that this is pretty the standard thing in the
  industry. Nothing too fancy. Very simple model based on the
  assumption of normality.

  Basically you have 23 risk factors:

  - Discretized term structure of interest rate using time buckets of
    0-2 years, 2-3 years, 3-4 years, 5-7 years, 7-10 years, 10-15
    years, 15-20 years, 20-30 years, 30 and more years.
  - Implied volatility of interest rates 
  - Exchange rates (FX): EUR/CHF, GBP/CHF, USD/CHF, JPY/CHF 
  - Implied volatility of FX rates 
  - Share price index (including dividends, modeled by one global index) 
  - Private Equity (modeled by one global index) 
  - Hedge Funds (modeled by one global index) 
  - Participations
  - Other equity
  - Implied volatility of share price index 
  - Property (residential and commercial) 
  - Credit spread (Investments and sub-investment grade)   

  All the risk factor changes are assumed to be normally distributed
  (with mean 0). The joint behavior of the risk factors is described
  by their covariance matrix. - See here the riskMetrics stuff.

  Changes in risk factors lead to changes in the risk bearing
  capital. For reasons of simplicity, it is assumed that the change in
  risk-bearing capital is a linear function of the risk factor
  changes.

  So basically your task is then to estimate the coeficient of this
  expression. You know well from your statistics classes the possible
  ways of doing it.

  Based on such model it is then possible to compute the possible
  volatility of your risk bearing capital and its modeled change in
  a change of risk factors.
  
  #+begin_export html
   <img src="../../images/Screenshot 2022-04-05 180045.png" class="center">
  #+end_export

** Simplifications

   So as well noted this standard model for asset valuation is quite
   simple. Will be interesting to now make a benchmark with the
   internal model but that is no info for the public.

   Note in any case that among the risk that such models do not
   include are:

   - Specific risks (country, industry, counterparty …)
   - Concentration risks 
   - Liquidity risks
   - non-linear risks due to the effect of derivatives in your portfolio

   #+begin_quote
If these nonlinear effects are relevant, then the appointed actuary
needs to model them appropriately, for instance by adjusting the
sensitivities, by defining scenarios or by some other method.
   #+end_quote

   So you see that this is a crude adjustment. I went and check the
   modeling team in Group Risk Management. Pretty solid backgrounds so
   I am sure they are doing cool stuff in order to model that.

   I guess that this might even be the responsibility of the MRA in my
   team. I guess I will discover in time.
   
** Calibration - Using Historic Data

   So you basically have to calculate the volatilities and historical
   sensitivities in order to have the parameterization of the model
   such that all of the rest will be a simple plug in and calculate
   exercise.

   #+begin_quote
To calibrate the volatilities and correlation matrix, monthly data is
used, if possible. In cases where the market is sufficiently liquid,
the volatilities can be estimated directly using observable data. In
cases where the market is illiquid, observed data has to be
supplemented or adjusted to take into account illiquidity or
intransparency.
   #+end_quote

   Note as well that some volatilities will be prescribed by the
   regulator. So you come back to [[*On the standard models][this]] types of parameters.

** Aggregation across Risks

   This is not interesting to your team as you stop when you produce
   your distribution and simulations of interest.

   In any case as a note to the interested reader you aggregate your
   probabilities distributions coming out of the different risks that
   you are modeling by means of convolution.
   
   #+begin_export html
    <img src="../../images/Screenshot 2022-04-06 085052.png" class="center">
   #+end_export

   This is interesting. Would have to read a little bit deeper. I
   would have thought that what you would actually do is produce these
   different risk values - say VaR or ES for the different segment and
   then just aggregate these.

   It seems that this is not the case in the chart above. It rather
   seem that you have a final distribution coming from the convolution
   of the others. You would then ultimately compute the risk measures
   from there.
   
*** QUESTION come back to it at some point                      :methodology:
   

* TODO Credit Risk in the Standard Models
  

* Scenarios and Aggregation with Standard Models

  So that is as well quite simple.

  There is just a shift into the quantile that is not as
  straightforward.

  I mean could not infer it from the source I am checking at but it is
  not explained there the methodology. You just have the
  formula. Would have to find some material where they explain the
  things a little bit more.

  Anyways getting back to sauce the situation is as follows:
  
  #+begin_export html
   <img src="../../images/Screenshot 2022-04-07 165148.png" class="center">
  #+end_export

  So read the target capital in the following way - much clearer then
  to get the idea - quite simple one.

  #+BEGIN_src latex :results drawer :exports results
\[ TC = ES_{\alpha^'} - \frac{p}{\alpha} * (ES_{\alpha^'} + \sum c_i * w_i) \]
  #+END_src

  #+RESULTS:
  :RESULTS:
\[ TC = ES_{\alpha^'} - \frac{p}{\alpha} * (ES_{\alpha^'} + \sum c_i * w_i) \]
  :END:

  So you basically see that it is the expected shortfall for that 
  adjusted quantile corrected by some additional risk occurring for
  the scenario case. 

  So that is pretty trivial. There are still some sign things that
  make such an interpretation a little bit confusing but I am pretty
  much sure that the ultimate idea behind it is that one.

  The only thing is that quantile adjustment. That looks pretty much
  arbitrary.
  
  #+begin_export html
   <img src="../../images/Screenshot 2022-04-07 170417.png" class="center">
  #+end_export

  

* Connecting the dots with your Risk System
  
** On the regular SST shocks that you get into the system

   So your guess was correct.

   The shocks that you are delivered by the FINMA regularly are done
   for creating one off calculations of bad situations that are then
   leveraged for making topside adjustments on your risk calculations.

   - Market consistent valuation: Best estimate (discounted cash flows +
     valuation of all relevant options and guarantees) and safety margin.

   - An alytical models for normal situation, scenarios take into
     account situation when models break down

   - Results of analytical models and scenarios are aggregated to arrive
     at target capita

     The aggregation: weighted (quantile-adjusted) average of scenarios
     with results from analytical mode.

*** Examples of Assets scenarios used by SST

    - Stock Market Crash 1987
    - Nikkei Crash 1989
    - European Currency Crisis 1992
    - US Interest Rates 1994
    - Russia / LTCM 1998
    - Stock Market Crash 2000
    - Default of reinsurer
    - etc.

* TODO note that you now got both methodological papers

  i.e. you got both Z-ECM and SST.

  So read the both and understand what exactly is different between
  them.

  this approach of understanding the thing at high level and then
  going down in the code is promising. I am starting to connecting
  quite many dots and you are slowly getting a very clear
  understanding of the thing.
  
