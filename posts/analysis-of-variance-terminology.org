#+BEGIN_COMMENT
.. title: Analysis of Variance - Terminology
.. slug: analysis-of-variance-terminology
.. date: 2019-09-22 14:24:02 UTC+02:00
.. tags: ANOVA
.. category: 
.. link: 
.. description: 
.. type: text
#+END_COMMENT

#+BEGIN_HTML
<br>
<br>
#+END_HTML

This is the first post making notes on the ANOVA - /analysis of
variance/.

The basic research question of the study of the ANOVA is how to
compare different research outputs and how to assess whether the
difference among two or more group outcomes are statistically
significant or rather the result of randomness. In this sense a
special attention is given to the *experimental error*, which
represent the natural variation and error observed in an untouched
environment from the unconditioned underlying data generating
process. Just with this notion of "true/underlying" randomness the
interpretation of the results is sensible.

This first post, starts to explore the above by making the point of
the difficulties underlying such studies and the importance of the
experimental settings which the researcher is exposed to. 

{{{TEASER_END}}}

*** Observational vs. Experimental Studies

Ideally, to make the best assessment on the significance of a specific
variable, we would rather work under /experimental/ settings. This
contrast with the case of /observational studies/, where the outcome
for different groups can be merely observed without any possibility
for the observer to control the environment the data generating
process lives in.

When researching the specific /ceteris paribus/ effect of a variable
on the observed outcome the difficulty of observational studies lies in
finding *cause-effect relationships*. 

Without the possibility of designing the study environment it might be
rather challenging for the researcher to *control* for underlying
factors influencing the one dataset or the other therefore affecting the
study results. In this, sense with observational data, we can
typically just make a statement about an /association/ between two
variables. The variable of interest might however not be the /unique/
thriving factor of the association as hidden /confounding variables/
might well be. Moreover, a causal claim is empirically difficult to
prove without a general subject understanding cause the causal link
might very well be from the outcome variable to the variable of
interest.

*** Experimental Studies: Design

In order to limit the issues mentioned above, experimental studies
should be properly designed, starting with a /focused and precise
research question/. The aim of an experimental study should be
the one of /confirming/ a certain specific conjecture rather than
/creating/ one. It is therefore important that you make sure ex-ante
of where you want to go.

Moreover it is necessary to properly define the following ingredients
of the experiment:

- *treatments*: different interventions that the researcher performs
  on the system (i.e. different fertilizer combinations.) There are
  different types of treatments in this sense:

  1. treatments that can be /varied to the researcher whims/.

  2. treatments that are /systematically recorded/.

  3. treatments that /can be kept constant/ and therefore which effect
     can be eliminated.

  4. treatments that can /neither be recorded nor kept constant/.

- *experimental units*: the /things-objects/ to which we apply the
  treatments (i.e. bonsai receiving fertilizer)

- *response*: the output that we measure (i.e. biomass)

A final important characteristic of experimental studies lies in
*randomization*. This ensures that the only systematic difference
among different treatments "groups" is the treatments itself.

Typically it is important to randomize over:

- the order (time dimension) in which experimental units are used. 

- the locations at which experimental units are used (if
  experimenting in different such locations)

If moreover you know firmly through your subject specific knowledge of
some systematic difference among different /experimental units/ it
makes sense then to just randomize *within* the homogenous block
(think for instance tropical vs. non-tropical bonsai). This process is
called /blocking/ and typically increase the /precision/ of an experiment.

Finally, note the different three cases with the associated different
terminology:

- *blinding*: just the researcher does not know about the assignment
  of different treatments when observing the data.

- *double blinding*: neither the researcher nor the study patients
  knows about the assignment of different treatments.

- *control treatment*: an untreated number of observations to which no
  treatment was assigned posing the benchmark and controlling for the
  natural experimental design.

- *placebo*: a neutral treatment indistinguishable from the proper
  treatment in order to keep the study patient balanced and unaffected
  after receiving the treatment or not. 

*** Literature

[[https://stat.ethz.ch/lectures/as19/anova.php#course_materials][ETHZ ANOVA lecture notes]]
