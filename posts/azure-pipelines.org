#+BEGIN_COMMENT
.. title: Azure Pipelines
.. slug: azure-pipelines
.. date: 2022-03-23 13:02:43 UTC+01:00
.. tags: azure, software-engineering
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT

#+begin_export html
<style>
img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}

.container {
  position: relative;
  left: 15%;
  margin-top: 60px;
  margin-bottom: 60px;
  width: 70%;
  overflow: hidden;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
  display:block;
  overflow-y: hidden;
}

.responsive-iframe {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
  width: 100%;
  height: 100%;
  border: none;
  display:block;
  overflow-y: hidden;
}
</style>
#+end_export

So write here a bit of documentation about how to create your DevOps
pipelines.

That will be important as in such a way you can finally abstract from
the lower level stuff.

You just deployed your first webapps on Azure. You did that through a
single gradle command through the gradle plug in.

So in this sense it is easy now to deploy your changes via such
pipelines. You can embedd this over there as a task theoretically.

Other people are taking the lead in this dimension and know much
better how to set up proper env integrated with Jira or similar
boards, so will not spend too much time with it.

This is not interesting to this stage for me. It is just a small test
in order to read pipelines and understand properly what is going on
over there such that you can understand the general workflow.

Note that obviously all of the notes under this page stems directly
from the official Microsoft documentation.

{{{TEASER_END}}}

** General Concepts

   So understand the following basic concepts - see [[https://docs.microsoft.com/en-us/azure/devops/pipelines/get-started/key-pipelines-concepts?view=azure-devops][here]].

   Check as well here in order to get a proper overview of the thing:
   
   #+begin_export html
    <img src="../../images/Screenshot 2022-03-23 132355.png" class="center">
   #+end_export

   So understand that it is essentially a hierarchy.

   #+begin_src plantuml :file ../../images/pipelineHierarchy.png :exports none
   @startmindmap
 * pipeline
 ** 1:N Stage \n\nA stage is a logical boundary in the pipeline. \n\nIt can be used to mark separation of concerns (for example, Build, QA, and production). 
 *** 1:N Job \n\n Jobs are most useful when you want to run a series of steps in different environments. \n\nFor example, you might want to build two configurations - x86 and x64. In this case, you have one stage and two jobs. 
 **** 1:N Step \n\nA step is the smallest building block of a pipeline. For example, a pipeline might consist of build and test steps. \n\nA step can either be a script or a task. 
 ***** 1:N Task \n\npre-packaged script performing actions.\n\nSay invoking REST API or pub artifact.
 ***** 1:N Script \n\nruns code as a step in your pipeline using command line, PowerShell, or Bash.

 *_ Where do Pipelines run? Where are they deployed?

 * <b>Agents</b> \n\nAn agent is computing infrastructure with installed agent software that runs one job at a time. \n\nFor example, your job could run on a Microsoft-hosted Ubuntu agent. \n\nThis info you specify in the <i>pool</i> section of your pipeline.

 * <b>Deployment Group</b> \n\nA deployment group is a set of deployment target machines that <b>have agents installed</b>.

 * <b>Deployment</b> \n\nCollection of steps that are run sequentially against an environment.

 * <b>Environment</b> \n\nAn environment is a collection of resources, where you deploy your application. \n\nIt can contain one or more virtual machines, containers, web apps, or any service that's used to host the application being developed.

 *_ Other important concepts in the pipelines - first class citenzens

 * <b>Approvals</b> \n\nIn such a way you pose your restrictions. \n\nI.e. validations before a deployment runs.

 * <b>Artifact</b> \n\nThis is the easier version of the docker images you were used to work with in your K8s wordl. \n\nAn artifact is a collection of files or packages published by a run. \n\nArtifacts are made available to subsequent tasks, such as distribution or deployment.


   @endmindmap
   #+end_src

   #+RESULTS:
   [[file:../../images/pipelineHierarchy.png]]

   #+begin_export html
    <img src="../../images/pipelineHierarchy.png" class="center">
   #+end_export

   All of the keywords you read into a pipeline refer to these
   first-class citizens of the webapp.

** CI/CD

   So all good.

   Now with the above concepts you can easily set up your pipeline.

   CI -> here you put all of the different constraints that ultimately
   lead you to the artifact creation if successful.

   You can then assemble the artifact and publish it.    

   CD -> deploy artifact if CI successful upon - each git pull into
   master etc.

** Tasks

   So the above is pretty it. Quite ok. You should be able to read
   pipelines to this stage.

   It is just a question of deciding what you want to do in there and
   properly setting up a workflow but the operations are
   clear. Especially in our not so big environment.

   Now understand this last bit and you will have more less a complete
   understanding of what is going on in the pipelines.

   You can pass your user defined tasks or use already packaged tasks
   that Azure make available to you.

*** Passing user defined tasks

    Note that this functions a bit like the image marketplace on K8s.

    You have a container registry there where you publish your images
    etc. Here is the same there is a VS-Marketplace where you publish
    your tasks.

    Ok - so weird stuff over there. Have a look ath [[https://docs.microsoft.com/en-us/azure/devops/extend/develop/add-build-task?view=azure-devops][here]].

    Did not loose too much time checking at it. Just by having a very
    quick look at it I understood it must not be that trivial.

    Plus it starts to talk about node etc. Well not my beer. I guess I
    will live with the packaged tasks as long as possible. Should be
    enough.

    Plus not in my focus point that bit of our tech stack.

*** Using packaged tasks
    
    In order to make your life easy Azure arrived a further level of
    abstraction providing you the possibility to leverage on already
    packaged tasks.

    You follow then a bit of DSL and you are done.

    Note that the =@<Nbr.>= are the versions of such packaged tasks.

    You can find the packaged tasks available [[https://docs.microsoft.com/en-us/azure/devops/pipelines/process/stages?view=azure-devops&tabs=yaml][here]].

    You see that what we used in the pipeline you have for your
    projects is mainly these.


    

   
   



** Using templates

   I am developing now the general setup for the Python stack. The
   essential idea is to create everything as code and have a complete
   build and release strategy for it. It goes more less along [[https://faun.pub/azure-devops-build-release-with-yaml-templates-d55f25a4928c][these lines]].

   You can read about parameter and how to consume them in the
   following two resources: [[https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops][one]], [[https://docs.microsoft.com/en-us/azure/devops/pipelines/process/runtime-parameters?view=azure-devops&tabs=script][two]].

   Check as well the existing project. There is a pipeline as well
   published there for the python projects. Note that there you do not
   publish artifacts. You rather archive things. So you can use it as
   reference but the solution is sub-optimal.

   Note that there you have [[https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=azure-devops&tabs=yaml][the service connection parameter]].
