#+BEGIN_COMMENT
.. title: GUnicorn Deployment Options
.. slug: gunicorn-deployment-options
.. date: 2022-04-25 11:16:23 UTC+02:00
.. tags: IT Architecture, software-engineering, Python
.. category: 
.. link: 
.. description: 
.. type: text

#+END_COMMENT

#+begin_export html
<style>

img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}

.container {
  position: relative;
  left: 15%;
  margin-top: 60px;
  margin-bottom: 60px;
  width: 70%;
  overflow: hidden;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
  display:block;
  overflow-y: hidden;
}

.responsive-iframe {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
  width: 100%;
  height: 100%;
  border: none;
  display:block;
  overflow-y: hidden;
}
</style>
 #+end_export

So basically this is closing the circle. With this post you should
gain the final understanding of the proper way of deploying a python
application in production, meaning it should give you a flavour of how
possible configurations settings that will affect the number of
requests that your application can handle as well your hardware
resources utilization.

So basically this post touches upon the topic of workers, threads
etc. and the way to configure everything. It is good to understand
this in the context of [[https://marcohassan.github.io/bits-of-experience/posts/on-multithreading/][this post]] as well.

{{{TEASER_END}}}

** Excurs - On mulitiprocessor architecture

   So in order to properly understand what is going on you must have a
   basic understanding of the concept of multi core processors.

   Understand the following:

   #+begin_quote
A multicore processor is an integrated circuit that has two or more
processor cores attached for enhanced performance and reduced power
consumption.

These processors also enable more efficient simultaneous processing of
multiple tasks, such as with parallel processing and multithreading.

A dual core setup is similar to having multiple, separate processors
installed on a computer. However, because the two processors are
plugged into the same socket, the connection between them is faster.
   #+end_quote

   In general the architecture is the following:

   #+begin_export html
    <img src="../../images/Screenshot 2022-04-25 130301.png" class="center">
   #+end_export

   Note that the grey boxes represent chip boundaries.

   The different chips are then connected via system bus and share the
   same memory.

   #+begin_export html
    <img src="../../images/Screenshot 2022-04-25 130544.png" class="center">
   #+end_export

   So basically the idea is that in environments where your
   infrastructure is of a multiprocessor type, you can run different
   processes at the same time.

   This in conrtrast to single-core architectures where you can run
   multiple processes only by scheduling means. This is for instace
   what happens in [[https://www.8bitavenue.com/difference-between-multiprogramming-multitasking-multithreading-and-multiprocessing/][multitasking]] in modern architectures.
   
** VMs

   Note now the different well known virtualization techniques you
   learned of at IBM actually do exactly this.

   By creating sets of virtual resources they package different
   subsets of multiprocessors architectures into virtual resources
   that can then be isolated from one another.

   So you have to check at your VMs as well when you program as this
   will be the basis for your "infrastructure" when running your
   programs and different programs will require different infra based
   on the reasoning of the previous section and how you set them up.

** Workers

   So with this basic content it will be possible to better understand
   the concept of workers in gunicorn servers and to set the amount
   correspondingly.

   In order to well understand it check at [[https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7][the following]].

   Basically what is important to get is the following:

   #+begin_quote
Each of the workers is a UNIX process that loads the Python
application. There is no shared memory between the workers.
   #+end_quote

   So basically the question is how many processes should you start on
   your server?

   The solution is the following as per the official GUnicorn guide:

   #+begin_quote
Gunicorn relies on the operating system to provide all of the load
balancing when handling requests. Generally we recommend (2 x
$num_cores) + 1 as the number of workers to start off with. While not
overly scientific, the formula is based on the assumption that for a
given core, one worker will be reading or writing from the socket
while the other worker is processing a request.
   #+end_quote

   And then, as stated in the article above:

   #+begin_quote
From that point, itâ€™s all trial and error with benchmarking.

If the bottleneck is memory, start introducing threads.

If the bottleneck is I/O, consider a different python programming
paradigm.

If the bottleneck is CPU, consider using more cores and adjusting the
workers value.
   #+end_quote

   You can then use your test-load tools for that.
   
** How to magically autoset that magic formula for the workers

   You can specify it programmatically in the [[https://docs.gunicorn.org/en/stable/settings.html#config-file][config file]]. (See the
   link to see where to put in your source code).

   You can then specify something as this in there:

   #+BEGIN_SRC python
import multiprocessing

workers = multiprocessing.cpu_count() * 2 + 1

#... other interesting parameters
   #+END_SRC
   
That is all folks for the moment. This is what I wanted to cover
   for this post.
