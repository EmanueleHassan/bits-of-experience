#+BEGIN_COMMENT
.. title: Integration and Asynchronous Jobs
.. slug: asynchronous-jobs
.. date: 2022-02-24 15:43:59 UTC+01:00
.. tags: java, IT Architecture, software-engineering, Integration
.. category: 
.. link: 
.. description: 
.. type: text
.. status: 

#+END_COMMENT

#+begin_export html
<style>
img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}

.container {
  position: relative;
  left: 15%;
  margin-top: 60px;
  margin-bottom: 60px;
  width: 70%;
  overflow: hidden;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
  display:block;
  overflow-y: hidden;
}

.responsive-iframe {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
  width: 100%;
  height: 100%;
  border: none;
  display:block;
  overflow-y: hidden;
}
</style>
#+end_export

So new post.

This is mainly about some integration exercise. It is not simple to
set up properly integration patterns. You can refer to [[https://www.enterpriseintegrationpatterns.com/index.html][the following]]
for a general overview.

So let's start to explore.

{{{TEASER_END}}}

So the basic idea is to create an integration pattern via
asynchronous API calls.

So you will need to pieces:

1. code implementation to work with that mental framework

2. asynchronous API documentation

The next two chapters deal with it.

(Update as of 10-03 - actually the best way to work in such an
asychronous way is through a ractive programming model. Check at your
notes in [[https://marcohassan.github.io/bits-of-experience/posts/spring/][here]] - chapter on reactive programming. Note however that
you will not be able to write full reactive programs as the relational
model and JDBC is not being rewritten in a reactive way yet.)
     
* Asynchronous API - Documentation

  Apparently there is an OpenAPI counterpart for async communication.

  I mean you could simply document your endpoints with OpenAPI and
  keep the structure of the async communication in some documentation
  somewhere else.

  I like in any case the idea of using a standard. Computer science is
  fun and you have to leverage on such big projects as then you can
  see that there are options to visulize this general asynch
  communication and more likely many other projects will start to
  emerge as this is just the beginning of the entire thingy. 

  Check [[https://www.asyncapi.com/docs/getting-started/hello-world][this]]. You see that it is a quite intuitive scema.

  Read into it [[https://www.asyncapi.com/blog/asyncapi_codegen_scst][here]] to get an idea of where the market is already
  moving.

  I think that this will come with time. Baby steps as always. Start
  easy - then expand on it. Sooner or later you will start in any case
  to work more with event-driven architectures. 


* Coding and Designing Asynchronous Communication 

  So basically there are two options:

  - polling

  - callback

  You can briefly read about the two [[https://sanketdaru.com/blog/polling-model-async-rest-spring-boot/][here]]. It is clear now that the
  most elegant option is the second one.

** Polling

   W.r.t. polling you can see the following two sources:

   - [[https://sanketdaru.com/blog/polling-model-async-rest-spring-boot/][source 1]]

   - [[https://github.com/PheaSoy/spring-boot-async-callback][source 2]] - note that name is misleading it is still mostly a
     polling solution in my view. 


** Callback

   You can easily create callbacks with a seris of endpoints and
   multi-threading on your machines.

   A more solid way is to work with queues. Then you do not have to go
   on multi-threading necessarily. This might simplify extensively the
   development task at the cost of some resources loss.

   You can then integrate queues with event-grids in order to create a
   fully reactive architecture for your application that is not
   polled operations dependent.

   I.e. in comparison to [[https://github.com/PheaSoy/spring-boot-async-callback][source 2]] you do not have the client to
   continuously ask for the feedback and check if execution completed.
    

* General Architecture for creating a scalable integrated ETL service
  
** First Round of Thinking - refinements are coming
   
   #+begin_src plantuml :file ../../images/callbackAsync.png :exports none
@startuml

''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'
' Object Definition
' - note that the elements below have to respect the order 
' - through which they will be triggered in the activity diagram
' - such that everything is well visible
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

participant     Loader               as BarraLoader
actor           BusinessUser         as "Business User"
queue           myBrokerPubSub       as myBrokerPubSub
queue           myBrokerQueue        as myBrokerQueue
collections     ETL                  as "scalable ETL Service"
database        Database             as marketRiskDB


''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'
' Activity Diagram
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

BusinessUser -> myBrokerQueue : UI triggering lambda with a given message \nwith the location of the new file.
BarraLoader  -> myBrokerQueue : lambda with a given message \nwith the location of the new file. 

myBrokerQueue -> ETL          : ETL services consuming the queues
ETL            -> marketRiskDB : storing the relvant infroamtion in the DB

ETL            -> myBrokerPubSub : Informing the job has been successful completed
myBrokerPubSub -> BusinessUser   : fan-out to business end users/ applications.\nSpecific job completed.
BusinessUser   -> marketRiskDB   : can withdraw the relevant inforamtion
@enduml
   #+end_src

   #+RESULTS:
   [[file:../../images/callbackAsync.png]]


   #+begin_export html
    <img src="../../images/callbackAsync.png" class="center">
   #+end_export

   I mean so you see that at conceptual level it is not that difficult
   to set up a solution performing your desired solutions.

   Have just to read a bit into it - but basically you are very much
   done.

   You can read over [[https://www.freecodecamp.org/news/how-to-scale-microservices-with-message-queues-spring-boot-and-kubernetes-f691b7ba3acf/][here]] a basic example for such a similar solution
   going more in the technological component. Note that you will
   not be able to apply the exact same tech stack but the idea is
   there and it is quite similar to what you had in mind. 

   Another [[https://developer.ibm.com/tutorials/auto-scale-rabbitmq-consumers-by-queue-size-on-openshift/][source]] for making that pattern.


** Second round of Thinking - gathering evidence

    So the one above was a basic idea.

    I think you have the general structure in mind. Have to become more
    concrete now.

    Explore better the available services in Azure and start to create
    a solid architecture for it.

    I.e. slowly start as well talks with your peers to see what is
    doable and what is not.

    Basic architectural patterns that you should consider for your
    asynchronous messages are [[https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/messaging][the following]].

*** Request-Reply Pattern

    Essentially what you aim to set up is an async request-reply
    integration pattern.

    You can read about it over [[https://docs.microsoft.com/en-us/azure/architecture/patterns/async-request-reply][here]]. There in the context and problem
    you can see your exact situation and see how a queue is often the
    solution architecture of choice for this kind of situations.

    Note that the queue must be integrated with a status check.

    You can see the most basic architecture to set something like this
    up [[https://reflectoring.io/amqp-request-response/][here]]. I think this is quite basic and I will try to construct a
    more solid architecture next. 

    This is what I will develop on in the next sections.

*** Service Bus

    This is a queue service in Azure. So it is a managed queue that it
    is easy to interact with.

    If you want to go fully open source check the resources
    above. Note as well that service bus is quite a simple message
    broker. I understand that it does not allow neither the
    flexibility of an exchange as RabbitMQ nor the resiliency of the
    cluster topology of Kafka. (See quick notes [[https://marcohassan.github.io/bits-of-experience/posts/spring/][here]]). 

    Important points for it are mentioned next. 
    
**** On operating the messages in a queue

     So essentially understand the following basic operations you can
     do with it:

     - get messages from queue

     - delete messages from queue

     - peek messages from queue

**** Getting the Messages
     
     Check at the following get operation for a message in the queue.

     #+begin_quote
 When a message is retrieved from the queue, the response includes
 the message and a pop receipt value, which is required to delete the
 message (have an API call for it).

 The message is *not automatically deleted from the queue*, but after
 it has been retrieved, it is *not visible to other clients* for the time
 interval specified by the *visibilitytimeout parameter*.
     #+end_quote

     Note that upon getting a message from the queue the =delivery
     count= is increased. This is of paramount importance to deal with
     faulty messages and a first class citizen for the concept of [[*Dead Latter][Dead
     Latter]]. 

     So in this way you can keep track of what was processed and what
     still needs to be processed. You have a state machine as long as
     the queue is reliable. Have to discuss with V. in this sense to
     question how important is that 0.01% of non-availability. I guess
     that for us is not a major concern as worst you do the operation
     again. Have to have a logging mechanismus keeping track of
     everything nonetheless. 

     Now the only thing is that in such a way you need polling from
     the queue.

     The other possibility is to set an event-grid or an azure
     function trigger in between.

**** Peeking the Messages

     This function essentially works as the get orperator with the
     difference that =delivery count= is *not increased*:

     #+begin_quote
  Service Bus allows a consumer to peek the queue and lock a message
  from other consumers.

  It's the responsibility of the consumer to *report the processing
  status* of the message.

  Only when the consumer marks the message as consumed, Service Bus
  removes the message from the queue.

  If a failure, timeout, or crash occurs, Service Bus unlocks the
  message so that other consumers can retrieve it. This way messages
  aren't lost in transfer.
     #+end_quote
     
**** Deleting the Messages

     As mentioned above in the two cases what you actually do in the
     above is reading messages out of the queue.

     You do not delete such from there. You just acquire a lock over
     them for a limited amount of time.

     Then you have to manually delete upon the successful processing
     of a message.

     You can well understand that this is very good as in such a case
     you have an actual state machine about the messages that are
     still to be completed.

     The question is rather how you log finished jobs. I guess that
     you are still interested in keeping track of that.

     Need to couple the thing with a store then.
     
**** Dead Latter

     See [[https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dead-letter-queues][here]].

     This is essentially a queue within the queue where unprocessed or
     errors-bounded messages are being stored.

     There are multiple reasons that make messages qualify as
     dead-latter messages.

     The most interesting one - among the many others - for your
     application logic is the following:

     - Maximum delivery count

       Recall that when you get the message out of the queue its count-value
       is incremented by one.

       Then after a given amount of times that you tried to process
       the message without success... i.e. when the count value is
       large enough - you start to push the message 

**** Note that there are ways to inspect the size of your queue

**** Check-pointing for long running jobs

     That is exactly the other bit that you need.

     You can set the state for a session and get the state.

     So with it you would already have a solution for the UI to get
     the relevant information about the processing status of a job.

     For more refer to the relevant section over [[https://docs.microsoft.com/en-us/azure/architecture/guide/technology-choices/messaging][here]].     

     
** Putting it all together

   #+begin_src plantuml :file ../../images/ETLstateMachine.png :exports none
@startuml

''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'
' Object Definition
' - note that the elements below have to respect the order 
' - through which they will be triggered in the activity diagram
' - such that everything is well visible
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

participant     Loader               as BarraLoader
actor           BusinessUser         as "Business User"

collections     BlobStore            as BlobStore

queue           EventGrid            as EventGrid
queue           ServiceBus           as ServiceBus
collections     ETL                  as "scalable ETL Services"
database        marketRiskDB         as marketRiskDB


''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
'
' Activity Diagram
'
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''

BusinessUser -> BlobStore : store new file - say for instance Feeds
BarraLoader  -> BlobStore : get files from Barra and save them in Blob

BlobStore    -> EventGrid  : publish message with new file location to be parsed
EventGrid    -> ServiceBus : store jobs messages in Azure Service Bus
ServiceBus   -> EventGrid  : fan out messages to consumer \n(note push logic instead of polling)


EventGrid      -> ETL          : ETL services consuming the Queue
ETL            -> ServiceBus   : Remove completed tasks from Queue
ETL            -> marketRiskDB : Store relevant data for the given job

ETL            -> EventGrid    : Publish the completition of some jobs \nunder a given topic.

EventGrid      -> BusinessUser : Informs (mail) subscribers of topic about successful completion of a given topic.
@enduml
   #+end_src

   #+RESULTS:
   [[file:../../images/ETLstateMachine.png]]

#+begin_export html
 <img src="../../images/ETLstateMachine.png" class="center">
#+end_export

   
   If you go for a push model you have to solve the following points:

   - pushing out of the queue - how do you trigger the eventGrid
     event if the message in the queue was not processed?

   - polling you can do it yourself by implementing ETL jobs pulling
     out from the queue. See the basic API of the bus.

   - check as well the option to work with Azure functions. It
     probably makes most sense to work in such a way.

     Check [[https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-storage-blob-triggered-function][this documentation]] in this sense. (actually the event Grid
     also mentioned [[https://stackoverflow.com/questions/47570207/message-from-azure-blob-storage-to-azure-service-bus][here]]). So in any case you are on the right track
     to construct your solution architecture. Check at [[https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-storage-queue-triggered-function][this]]
     documentation.

   - you need to check at the costs. you need Premium Service Bus if
     you want to go down the full road. Check if this makes sense but
     yeah probably makes sense to work with functions. 

**** on service bus - eventgrid integration

     See the [[https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-to-event-grid-integration-concept?tabs=event-grid-event-schema][following page]].

**** TODO open questions - how to make the service resilient

     
* On Azure Functions

  Very nice way to integrate with the two services you want to use:

  - Blob

  - Service Bus

  Check here the [[https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-service-bus][possible triggers]].

  In such a way you do not have to go Premium on Event Grid and I
  think that for the extent of our workloads it is more than enough to
  work in such a way without going too big on services.

  Start to test your workflow with Azure Functions Core Tools as soon
  as you get the green light from IT to install it. 


* On issues when working in such a fragmented Networking driven space
    
*** Circuit Breaker

    This is an important concept that you have to keep in mind when
    you develop your distributed system solution. 

    The idea is that as information is more distributed it might be
    more difficult to revert a given app bit of logic in case of
    errors.

    So you have always to keep in mind how to break the circuit in
    case of faults and how to revert every distributed component
    affected.

    You might as well think in terms of *compensating transaction*
    patterns.

    What is needed to track and trigger compensating transactions?

    This is in fact probably the one and major issue of setting up
    everything properly in a distributed system way. All the rest is a
    gain in my humble opinion. Especially on the long run. 

    Note that you can use DBs to manage state. You can think for
    instance of the solution

    Another possibility - and this a thing that in any case you will
    have to dig more into it - is the one of using frameworks as
    [[*Jaeger][Jaeger]].

    This might help you not simply for circuit breakers but as well to
    debug a distributed application and understand where issues and
    triggers are. 


*** Jaeger

    Helps to set up proper circuit breakers.

    The idea is that with Jaeger you can trace the calls back and
    implement your circuit breaker on the top of it.

    See the [[https://www.jaegertracing.io/][official documentation]]. Check as well other source as the [[https://reflectoring.io/spring-boot-tracing/][following]] for instance.

    Sooner or later if you start to have serious work in distributed
    environment that bit will come. 


