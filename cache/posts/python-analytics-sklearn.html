<p>
This is a repository where I hold some notes about the major sklearn
analytics algorithm in order to perform your data science. 
</p>

<p>
It is essentially an exercise into the <a href="https://scikit-learn.org/stable/modules/classes.html">sklearn API</a>. 
</p>

<p>
If you have it well in mind than you have well in mind the major ML
algorithms, the way to preprocess the data and the way create robust
pipelines.
</p>


<!-- TEASER_END -->


<div id="outline-container-org6c02428" class="outline-2">
<h2 id="org6c02428">General Pattern</h2>
<div class="outline-text-2" id="text-org6c02428">
<p>
The standard way of working with your data is first performing the
relevant exploratory data.
</p>

<p>
For it you can refer to the relevant separate post.
</p>

<p>
There you would inspect the data both analytically as well as
visually.
</p>

<p>
The goal is to understand what is available in the data.
</p>

<p>
The distribution of the data etc. 
</p>

<p>
In such a way it would be possible for you to create the relevant
features from the data. 
</p>

<p>
When creating the features it will be important to <b>transform</b> the
data such that they take a meaningful shape. 
</p>

<p>
You might need to one-hot-encode, standardize, impute etc.  
</p>

<p>
Note that you might fit data as well in order to get to the
transform the data accordingly. In this sense, you will find a
<code>fit_transform</code> API in sklearn.
</p>

<p>
After the data have been properly transformed it is time to fit the
actual analytical model. Here you would take one of the relevant
<b>supervised</b> / <b>unsupervised</b> models and you would ultimately fit
them to the main chunck of the data.
</p>

<p>
Finally, you would estimate / predict a new existing chunck of the
data given your fitted model and its parameters.
</p>
</div>
</div>


<div id="outline-container-org53e2906" class="outline-2">
<h2 id="org53e2906">The preprocessor object</h2>
<div class="outline-text-2" id="text-org53e2906">
<p>
In order to pre-process the data sklearn offers the preprocessor
object class.
</p>

<p>
There you have many different APIs that are useful in order to
process the data.
</p>

<p>
We will explore them next.
</p>
</div>

<div id="outline-container-orga0207d3" class="outline-3">
<h3 id="orga0207d3">Dataset</h3>
<div class="outline-text-3" id="text-orga0207d3">
<p>
In this section I will work with the datasets shipped with the
sklearn package.
</p>

<p>
In order to use the data use the following:
</p>

<div class="highlight"><pre><span></span>   from sklearn.datasets import fetch_california_housing as fdh
   import pandas as pd
   import numpy as np
</pre></div>

<div class="highlight"><pre><span></span>   df_housing = fdh (as_frame=1) [&#39;data&#39;]

   df_housingValue = fdh (as_frame=1)[&#39;target&#39;]

   df_housing.head (5)
</pre></div>
</div>
</div>



<div id="outline-container-org8979009" class="outline-3">
<h3 id="org8979009">Binarizer</h3>
<div class="outline-text-3" id="text-org8979009">
<p>
This converts data into binary given a certain threshold. 
</p>

<p>
You could for instance create a future in the above for checking
whether the data are in the northern hemisphere or in the
southern one in the following way:
</p>

<div class="highlight"><pre><span></span>   from sklearn.preprocessing import Binarizer
</pre></div>

<div class="highlight"><pre><span></span>   binary = Binarizer () ## note that it holds a parameter threshold. The
			 ## default is 0 and is good for the exercise of
			 ## Northern and Southern Hemisphere.

   binary.fit (np.array (df_housing [&quot;Latitude&quot;]).reshape (-1,1)) ## Note
								  ## that
								  ## the
								  ## Binarizer
								  ## takes
								  ## a 2D
								  ## array
								  ## as
								  ## input. You
								  ## therefore
								  ## need
								  ## to
								  ## reshape
								  ## your
								  ## data
								  ## and
								  ## wrap
								  ## your
								  ## array
								  ## into
								  ## a
								  ## list.
</pre></div>


<div class="highlight"><pre><span></span>   df_housing [&quot;Northern Hemisphere&quot;] = 
      binary.transform (np.array
			(df_housing
			 [&quot;Latitude&quot;]).reshape
			(-1,1)).
      flatten() ## Flatten out back to a 1D array
</pre></div>


<div class="highlight"><pre><span></span>   df_housing.head (5)
</pre></div>



<p>
Note that you can specify the threshold yourself. Think about the
case of Housing age. You want to create a binary if older than
the age or not.
</p>

<p>
You can then use the following:
</p>

<div class="highlight"><pre><span></span>   df_housing [&quot;OldHouse&quot;] = Binarizer (threshold= df_housing.HouseAge.mean ()) \
			     .fit_transform (np.array (df_housing [&quot;HouseAge&quot;]).reshape (-1,1)).flatten ()
</pre></div>


<div class="highlight"><pre><span></span>   df_housing.head (10)
</pre></div>
</div>
</div>


<div id="outline-container-org9b61b2b" class="outline-3">
<h3 id="org9b61b2b">QuantileTransformer</h3>
<div class="outline-text-3" id="text-org9b61b2b">
<p>
Note that this estimates the quantiles according to a parameteric
distribution that you impose on the data. 
</p>

<p>
It does not compute the quantiles based on the empirical
distribution of the data. Check in this sense the <code>qcut</code> method.
</p>

<p>
Note that this preprocessor function allows to estimate and fit
the quantiles of a uniform and normal distribution.
</p>

<div class="highlight"><pre><span></span>   from sklearn.preprocessing import QuantileTransformer
</pre></div>

<p>
So note that the exercise is different in comparison to the
quantile cut.
</p>

<p>
The idea is to compute <code>n_quantiles</code> quantiles from the actual
data. And then interpolate across them according to a
distribution of choice - be uniform or normal - in order to
compute the rest of the quantiles.
</p>
</div>


<div id="outline-container-org97450bf" class="outline-4">
<h4 id="org97450bf">Plot histogram of the data</h4>
<div class="outline-text-4" id="text-org97450bf">
<p>
In order to properly understand the operation we first plot the
histogram.
</p>

<p>
From it you can immediately infer that the data is log-normally
distributed.
</p>

<div class="highlight"><pre><span></span>    import matplotlib.pyplot as plt
    %matplotlib inline 
    %config InlineBackend.figure_format = &#39;png&#39;
</pre></div>

<div class="highlight"><pre><span></span>    plt.hist(df_housingValue, bins = 20)
</pre></div>

<img src="../../images/HistogramHousing.png" class="center">

<p>
We check next to the quantiles and the QuantileTransformer in
order to properly understand what operations the two perform on
the data.
</p>
</div>
</div>

<div id="outline-container-org4bdf516" class="outline-4">
<h4 id="org4bdf516">Quantile Transformation</h4>
<div class="outline-text-4" id="text-org4bdf516">
<p>
Note that weird distribution with heavy outliers or skewed
distribution might be sub-optimal in order to fit statistical
models to your data.
</p>

<p>
This because they the parameter estimation might be biased by
such properties of the data.
</p>

<p>
In this sense it makes often sense to inspect the data and
create new features that are less likely to bias your results.
</p>
</div>

<ul class="org-ul">
<li><a id="org377be04"></a>Plot the relevant transformer<br />
<ul class="org-ul">
<li><a id="org0adf917"></a><span class="todo TODO">TODO</span> go over again in a better fashion over the data.<br />
<div class="outline-text-6" id="text-org0adf917">
<p>
It imposes a distribution on the data. It estimates the
parameters of the distribution, given the empirical
distribution.
</p>

<p>
It then computes the quantiles for the data values given that
assumed distribution. 
</p>

<p>
If you plug then the values in the quantile transforming
function you would get back normalized values.
</p>

<p>
It transforms the data x in quantiles such that they fit the
relevant distribution.
</p>

<p>
Note that even such transformation has limits. See the
histogram plot that you created.
</p>


<p>
It is a transformation that tries to achieve a uniform
distribution of the assigned quantiles.
</p>

<div class="highlight"><pre><span></span>      plt.hist (QuantileTransformer(n_quantiles=5,
				    random_state=0).
		fit_transform (np.array (df_housingValue).
			       reshape(-1,1)).
		flatten (), 20) 
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-orga85edfa" class="outline-3">
<h3 id="orga85edfa">Standard Scaler</h3>
</div>



<div id="outline-container-orgde165fc" class="outline-3">
<h3 id="orgde165fc">MaxAbsScalerp</h3>
</div>



<div id="outline-container-org9079094" class="outline-3">
<h3 id="org9079094">LabelEncoder</h3>
</div>



<div id="outline-container-org5c721e3" class="outline-3">
<h3 id="org5c721e3">OneHotEncoder</h3>
</div>



<div id="outline-container-orgaf23dbf" class="outline-3">
<h3 id="orgaf23dbf">KernelCenterer</h3>
</div>



<div id="outline-container-org87eef9c" class="outline-3">
<h3 id="org87eef9c">FunctionTransformer</h3>
</div>



<div id="outline-container-orgad15fd8" class="outline-3">
<h3 id="orgad15fd8">FunctionTransformer</h3>
</div>
</div>




<div id="outline-container-org673b432" class="outline-2">
<h2 id="org673b432">Linear Regression</h2>
<div class="outline-text-2" id="text-org673b432">
</div>

<div id="outline-container-org157c158" class="outline-3">
<h3 id="org157c158">Data</h3>
<div class="outline-text-3" id="text-org157c158">
<div class="highlight"><pre><span></span>   import pandas as pd
   import numpy as np
   from matplotlib import pyplot as plt

   # Generate &#39;random&#39; data
   np.random.seed(0)
   X = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5
   res = 0.5 * np.random.randn(100)       # Generate 100 residual terms
   y = 2 + 0.3 * X + res                  # Actual values of Y

   # Create pandas dataframe to store our X and y values
   df = pd.DataFrame(
       {&#39;X&#39;: X,
	&#39;y&#39;: y}
   )

   # Show the first five rows of our dataframe
   df.head()
</pre></div>
</div>
</div>


<div id="outline-container-org0ef5b9c" class="outline-3">
<h3 id="org0ef5b9c">Getting the Regression Coefficients Manually via Analytical Solution</h3>
<div class="outline-text-3" id="text-org0ef5b9c">
<p>
Get the relevant coefficients of the regression:
</p>

<div class="highlight"><pre><span></span>   # Calculate the mean of X and y
   xmean = np.mean(X)
   ymean = np.mean(y)

   # Calculate the terms needed for the numator and denominator of beta
   df[&#39;xycov&#39;] = (df[&#39;X&#39;] - xmean) * (df[&#39;y&#39;] - ymean)
   df[&#39;xvar&#39;] = (df[&#39;X&#39;] - xmean)**2

   # Calculate beta and alpha
   beta = df[&#39;xycov&#39;].sum() / df[&#39;xvar&#39;].sum()
   alpha = ymean - (beta * xmean)
   print(f&#39;alpha = {alpha}&#39;)
   print(f&#39;beta = {beta}&#39;)
</pre></div>


<div class="highlight"><pre><span></span>   ypred = alpha + beta * X
</pre></div>
</div>

<div id="outline-container-org02e1520" class="outline-4">
<h4 id="org02e1520">Matplotlib of regression</h4>
<div class="outline-text-4" id="text-org02e1520">
<p>
Plot the relevant results:
</p>

<div class="highlight"><pre><span></span>    import matplotlib.pyplot as plt
    %matplotlib inline 
    %config InlineBackend.figure_format = &#39;png&#39;
</pre></div>


<div class="highlight"><pre><span></span>    # Plot regression against actual data
    plt.figure(figsize=(12, 6))
    plt.plot(X, ypred)     # regression line
    plt.plot(X, y, &#39;ro&#39;)   # scatter plot showing actual data
    plt.title(&#39;Actual vs Predicted&#39;)
    plt.xlabel(&#39;X&#39;)
    plt.ylabel(&#39;y&#39;)

    plt.show()
</pre></div>

<img src="../../images/Regression.png" class="center">
</div>
</div>
</div>


<div id="outline-container-org6d61a5f" class="outline-3">
<h3 id="org6d61a5f">Model Fit and Prediction</h3>
<div class="outline-text-3" id="text-org6d61a5f">
</div>
<div id="outline-container-org421103d" class="outline-4">
<h4 id="org421103d">The standard way to fit and predict in skit-learn</h4>
<div class="outline-text-4" id="text-org421103d">
<div class="highlight"><pre><span></span>    from sklearn.linear_model import LinearRegression

    # Initialise and fit model
    lm = LinearRegression()
    model = lm.fit(X.reshape(-1, 1), y)
</pre></div>


<div class="highlight"><pre><span></span>    print(f&#39;alpha = {model.intercept_}&#39;)
    print(f&#39;betas = {model.coef_}&#39;)
</pre></div>


<div class="highlight"><pre><span></span>    model.predict(X.reshape(-1, 1))
</pre></div>
</div>
</div>
</div>
</div>
