<p>
Pipelines are important when working on ML projects in python. They
first appeared through the implementation of ML tasks sklearn. There
the design setting of the maintainer of the library was to design a
set of APIs through which to govern the entire ML process. The three
major class of APIs are <code>tranformers</code>, i.e. transformations to the
feature and dependent variables, <code>estimators</code>, i.e. the ML model that
you fit on your transformed features matrix, and finally <code>predictors</code>,
i.e. the API method used for predicting your desired variable based on
your fitted estimator.
</p>

<p>
The above logic became so widespread that further important
libraries - such as the spark ML modules for using ML models
leveraging the spark engine for distributed computation - decided to
keep the same design setting and keep the above API structure.
</p>

<p>
This posts aims at keeping an overview of some important transformers,
estimators and predictors as well as to set up the general framework
to combine the three together in easy to use Pipelines. 
</p>

<!-- TEASER_END -->

<br>
<br>

<div id="outline-container-orgcb09f76" class="outline-2">
<h2 id="orgcb09f76">The general Case</h2>
<div class="outline-text-2" id="text-orgcb09f76">
<p>
In fact, all of the ML models in the sklearn and Spark-ML libraries -
for instance RandomForest, SVM, LogisticRegression etc. - are built
according to the three general <code>APIs</code> mentioned above. It is therefore
clear that given this design setting you can formulate your model as
following:
</p>

<ul class="org-ul">
<li>choose your transformers</li>

<li>fit your tranformers</li>

<li>transform the data</li>

<li>choose your ML model</li>

<li>fit your ML Model to the transformed data</li>

<li>use predictors to achieve your goals.</li>
</ul>

<p>
Your goal will then be to apply all of the above steps given your
application and to combine them into Pipelines that are easy to work
with in production.
</p>

<br>
</div>
</div>


<div id="outline-container-org9f7871e" class="outline-2">
<h2 id="org9f7871e">An Example with Pipeline Understanding</h2>
<div class="outline-text-2" id="text-org9f7871e">
<p>
A simple basic example that aims to provide your with the general
workflow is the following:
</p>

<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">median_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="c1">## notice the elegance of the sklearn library. you have different</span>
<span class="c1">## modules - model_selection, ensemble, pipeline, feature_selection</span>
<span class="c1">## etc.- that exposes the user directly to the logic of each method.</span>

<span class="c1">## load the boston dataset</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>

<span class="c1"># split in training and testing dataset - i.e. look at generalization</span>
<span class="c1"># of your model out of sample</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># create your pipeline that you can apply directly to your data. you</span>
<span class="c1"># can then fit the pipeline and predict using it.</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> <span class="c1">## standardize your</span>
					       <span class="c1">## data according to</span>
					       <span class="c1">## the normal</span>
					       <span class="c1">## standardization. </span>
		 <span class="p">(</span><span class="s2">&quot;featsel&quot;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)),</span> <span class="c1">## notice that this</span>
						 <span class="c1">## selectes the 10</span>
						 <span class="c1">## feutures that</span>
						 <span class="c1">## explain the most</span>
						 <span class="c1">## of the variance in</span>
						 <span class="c1">## the predictor</span>
						 <span class="c1">## variable. it is</span>
						 <span class="c1">## based on a</span>
						 <span class="c1">## multiple ANOVA</span>
						 <span class="c1">## given the</span>
						 <span class="c1">## different</span>
						 <span class="c1">## features.</span>
		 <span class="p">(</span><span class="s2">&quot;rf&quot;</span><span class="p">,</span><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">))])</span> <span class="c1">## specify</span>
								 <span class="c1">## a</span>
								 <span class="c1">## fit</span>
								 <span class="c1">## via</span>
								 <span class="c1">## a</span>
								 <span class="c1">## RandomForest</span>
								 <span class="c1">## with</span>
								 <span class="c1">## 20</span>
								 <span class="c1">## estimated</span>
								 <span class="c1">## bootstrapped</span>
								 <span class="c1">## trees</span>

<span class="c1">## train the data</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">## evaluate the model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;R^2=</span><span class="si">%.2f</span><span class="s1">, MAE=</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)))</span>
</pre></div>

<p>
Notice that you could have performed the above also without pipelining
all of the different methods
</p>

<div class="highlight"><pre><span></span><span class="c1">## Scale the data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="c1"># print(X_train.shape)</span>
<span class="c1"># print(y_train.shape)</span>

<span class="c1">## merge the data and apply the scaler on the entire matrix in one shot</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">379</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>

<span class="c1"># print (train.shape)</span>

<span class="n">scaled_fit</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">train</span><span class="p">)</span>

<span class="n">scaled</span> <span class="o">=</span> <span class="n">scaled_fit</span><span class="o">.</span><span class="n">transform</span> <span class="p">(</span><span class="n">train</span><span class="p">)</span>

<span class="n">featsel_fit</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">scaled</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">13</span><span class="p">],</span> <span class="n">scaled</span><span class="p">[:,</span> <span class="mi">13</span><span class="p">])</span>

<span class="n">featsel</span> <span class="o">=</span> <span class="n">featsel_fit</span><span class="o">.</span><span class="n">transform</span> <span class="p">(</span><span class="n">scaled</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">13</span><span class="p">])</span>

<span class="c1"># the extracted 10 features</span>
<span class="c1"># print (featsel.shape)</span>

<span class="c1">## Fit the data</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span> <span class="p">(</span><span class="n">featsel</span><span class="p">,</span> <span class="n">scaled</span><span class="p">[:,</span> <span class="mi">13</span><span class="p">])</span>


<span class="c1"># get corrected testing data</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span> <span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">ttt</span> <span class="o">=</span> <span class="n">scaled_fit</span><span class="o">.</span><span class="n">transform</span> <span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">featsel_fit</span><span class="o">.</span><span class="n">transform</span> <span class="p">(</span><span class="n">ttt</span><span class="p">[:,:</span><span class="mi">13</span><span class="p">])</span>

<span class="c1"># print (X.shape)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span> <span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># print (y_pred.shape)</span>

<span class="c1"># print (ttt[:, 13].shape)</span>

<span class="n">ttt1</span> <span class="o">=</span> <span class="n">scaled_fit</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">ttt</span><span class="p">)</span>

<span class="n">ttt2</span> <span class="o">=</span> <span class="n">scaled_fit</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">ttt</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">13</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">),</span><span class="mi">1</span><span class="p">))))</span>


<span class="c1">## Get your metrics for the fit</span>

<span class="k">print</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;R^2=</span><span class="si">%.2f</span><span class="s1">, MAE=</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">ttt1</span><span class="p">[:,</span><span class="mi">13</span><span class="p">],</span> <span class="n">ttt2</span><span class="p">[:,</span><span class="mi">13</span><span class="p">]),</span> 
			     <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">ttt1</span><span class="p">[:,</span><span class="mi">13</span><span class="p">],</span> <span class="n">ttt2</span><span class="p">[:,</span><span class="mi">13</span><span class="p">])))</span>

<span class="c1"># print (scaled_X.shape) ## we have 13 features</span>
<span class="c1"># print (scaled_X)</span>
</pre></div>


<p>
Notice that the results for the above are comparable to the one
obtained above. So you get the idea of what is behind a pipeline.
</p>

<p>
You fit all of the transformers and your predictor given your training
data. You then apply such fit to the training data. You scale back
your data and you compute the metrics on the original scaled data.
</p>
</div>
</div>
