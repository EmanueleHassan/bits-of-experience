<style>
img {
display: block;
margin-top: 60px;
margin-bottom: 60px;
margin-left: auto;
margin-right: auto;
width: 70%;
height: 100%;
class: center;
}

.container {
  position: relative;
  left: 15%;
  margin-top: 60px;
  margin-bottom: 60px;
  width: 70%;
  overflow: hidden;
  padding-top: 56.25%; /* 16:9 Aspect Ratio */
  display:block;
  overflow-y: hidden;
}

.responsive-iframe {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
  width: 100%;
  height: 100%;
  border: none;
  display:block;
  overflow-y: hidden;
}
</style>


<p>
So recently I had an interview for a quantitative finance
position. I completely failed the preparation as it was not at all
about financial instruments but much more about econometrics.
</p>

<p>
Anyways, here the notes I did for this preparation session. I
mainly prepared following <a href="https://www.efinancialcareers.co.uk/news/finance/the-50-market-risk-interview-questions-you-need-to-anticipate">these notes</a> as I was told that one of the
interviewer would be of the market risk division.
</p>

<p>
In fact, it turned out that this is a super nice team but is much
more about times series and econometrics than classical market risk
theory as you are being taught in University.
</p>

<!-- TEASER_END -->


<div id="outline-container-org0e30db8" class="outline-2">
<h2 id="org0e30db8">Some Mathematical Definitions</h2>
<div class="outline-text-2" id="text-org0e30db8">
<ul class="org-ul">
<li><p>
Cointegration:
</p>

<p>
First, all of the series must be integrated of <b>order d</b> (see
Order of integration).
</p>

<p>
Next, if a linear combination of this collection is integrated of
order less than d, then the collection is said to be
co-integrated.
</p></li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-17_um_09.19.20.png" class="center">

<p>
For integrated I (1) processes, Granger and Newbold showed that
de-trending does not work to eliminate the problem of spurious
correlation, and that the superior alternative is to check for
co-integration.
</p>

<p>
usual procedure for testing hypotheses concerning the relationship
between non-stationary variables was to run ordinary least squares
(OLS) regressions on data which had been differenced. This method
is biased if the non-stationary variables are cointegrated.
</p>

<ul class="org-ul">
<li><p>
P-value:
</p>

<p>
In null hypothesis significance testing, the p-value is the
probability of obtaining test results at least as extreme as the
results actually observed, under the assumption that the null
hypothesis is correct.
</p></li>

<li>Stationarity: this is a needed characteristics of times series
that makes them tractable from a statistical point of view. It
guarantees that there are some traits that guarantee a certain
stability of the series such that it is possible to arrive at
statistical conclusion.

<ul class="org-ul">
<li>Weak stationarity: if the process moments are stable over
multiple time horizons. I.e. time shifts do not change the first
couple of moments</li>

<li>Strong stationarity: if the process follows the same
distribution under time shifts. Difficult if not impossible to
check in practice.</li>
</ul></li>

<li><p>
Goodness of Fit: it is a measure how well a statistical model fits
a set of observations.
</p>

<p>
You can then use for instance information criteria, R<sup>2</sup> for
regression etc.
</p></li>

<li><p>
Regression:
</p>

<p>
is a set of statistical processes for estimating the relationships
between a <b>dependent variable</b> (often called the 'outcome
variable') and <b>one or more independent variables</b> (often called
'predictors', 'covariates', or 'features').
</p>

<p>
You can then have different types of regression:
</p>

<ul class="org-ul">
<li>linear regression</li>

<li>generalized linear regression</li>

<li>non-parametric regression</li>
</ul></li>

<li><p>
Risk-neutral:
</p>

<p>
There are the three components: Risk Adverse, Risk Neutral and
Risk Lover. The utility function of the investor defines his risk
appetite. In finance and economics you usually assert that the
investors are risk-adverse.
</p>

<p>
Then because of this it becomes difficult to price
securities. However in this sense the fundamental theorem of
arbitrage is helpful. This together with risk-neutrality allows to
price securities in a meaningful way.
</p>

<p>
As if there is no risk in the investment, due to the fundamental
theorem of asset pricing you cannot make any arbitrage,
i.e. profit without taking any risk. I.e. you must earn the risk
free rate. Like this you can price stuff.
</p></li>
</ul>
</div>
</div>


<div id="outline-container-org520a95f" class="outline-2">
<h2 id="org520a95f">Different Types of Risk</h2>
<div class="outline-text-2" id="text-org520a95f">
<ul class="org-ul">
<li>Credit Risk</li>

<li>Market Risk</li>

<li>Liquidity Risk</li>

<li>Operational Risk</li>
</ul>
</div>
</div>


<div id="outline-container-orgbb6c123" class="outline-2">
<h2 id="orgbb6c123">Quantitative Risk</h2>
<div class="outline-text-2" id="text-orgbb6c123">
<p>
At city they have the following divisions:
</p>

<ul class="org-ul">
<li>Market Risk Analytics</li>

<li>Counterparty Risk Analytics</li>

<li>Credit Risk Analytics</li>

<li>Economic Forecasting</li>

<li>Risk Capital Analytics</li>

<li>Model Governance and Stress Testing</li>
</ul>
</div>
</div>


<div id="outline-container-org26934e1" class="outline-2">
<h2 id="org26934e1">On tail dependency</h2>
<div class="outline-text-2" id="text-org26934e1">
</div>
<div id="outline-container-orga85fe24" class="outline-4">
<h4 id="orga85fe24">Copula</h4>
<div class="outline-text-4" id="text-orga85fe24">
<p>
Here are some quick and dirty notes about the copulas. 
</p>

<p>
These are handy when modeling the dependency of data in that they
allow to come to the multivariate distribution of data by working
sequentially with the individual marginal distributions and with
the copula (cumulative) distribution, the distribution expressing the
CDF (and therefore the dependency) among the marginal CDF distributions. 
</p>

<p>
More formally you can state:
</p>

<img src="../../images/Screenshot 2023-06-08 151139.png" class="center">

<p>
So you see that the copula focuses on the dependency structure by
focusing on the joint distribution of the CDFs. 
</p>

<p>
In this sense you can generate a sample for the dependency of the
CDFs by generating a sample via the marginal of choice and then
through the marginal obtaining uniformly distributed RV.
</p>

<p>
You can then compute the following:
</p>

<img src="../../images/Screenshot 2023-06-09 140418.png" class="center">

<p>
You would have then a set of probabilities for the event that you
can compare with existing copulas. Or through which you can
estimate the parameters of a given copula.
</p>
</div>


<ul class="org-ul">
<li><a id="org82b338a"></a>Sklar's Theorem<br />
<div class="outline-text-5" id="text-org82b338a">
<p>
This theorem is the one that proves that the approach above is
correct. 
</p>

<p>
In fact it states the following:
</p>

<img src="../../images/Screenshot 2023-06-09 142825.png" class="center">
</div>
</li>


<li><a id="org22ab374"></a>Families of Copulas<br />
<div class="outline-text-5" id="text-org22ab374">
<p>
You can then work with different families of copulas in order to
model the dependency across your data.
</p>

<p>
The common parameteric families are the following:
</p>

<img src="../../images/Screenshot 2023-06-09 143211.png" class="center">

<p>
From the discussion above it is clear how you can estimate such
parameters and work with such families in order to inspect
general dependencies (and possibly tail dependencies) in the
data.
</p>
</div>
</li>
</ul>
</div>
</div>


<div id="outline-container-org7ee58bc" class="outline-2">
<h2 id="org7ee58bc">Derivatives Pricing - Black Scholes</h2>
<div class="outline-text-2" id="text-org7ee58bc">
<p>
So this seems to be another quite interesting topic when they make
you interview questions for different jobs. 
</p>

<p>
So it is worth going over them again and make some notes here such
that you can quickly go over them again when necessary. 
</p>

<p>
The notes are mainly based on Hull book about derivatives, options etc.
</p>
</div>


<div id="outline-container-org624d18a" class="outline-4">
<h4 id="org624d18a">Brownian Motion / Wiener Process</h4>
<div class="outline-text-4" id="text-org624d18a">
<p>
This has been originally been defined in physics in order to model
the motion of a particle that is subject to a large number of
small molecular shocks.
</p>

<p>
The characteristics of such process are a mean of zero and
<code>variance</code> 1 per unit of time. 
</p>

<p>
The shocks are i.i.d. and hence the variance sums in time. 
</p>

<p>
This essentially mean that the <code>standard deviation</code> is <i>one per
square root of time</i>.
</p>

<p>
Now note that the process follows a normal distribution such that,
the process can be generally described as follows.
</p>

<img src="../../images/Screenshot 2023-06-09 152450.png" class="center">

<p>
Now this process works well for describing the returns, these are
i.i.d. and their variance is expected to increase in time.
</p>

<p>
We also know that assuming a normal distribution for the expected
price in the future is not a bad assumption. 
</p>

<p>
On the top of it we know that there is no free lunch in financial
markets such that the price in the future should be Markov -
i.e. only the present state is important for predicting the
future, the path taken is not.
</p>

<p>
However there is the beta of the market and that should somehow be
registered in the way we model stock prices. 
</p>

<p>
This brings us to the geometrical brownian motion. 
</p>
</div>
</div>


<div id="outline-container-org54be57f" class="outline-4">
<h4 id="org54be57f">Geometric Brownian Motion / Generalized Wiener Process</h4>
<div class="outline-text-4" id="text-org54be57f">
<img src="../../images/Screenshot 2023-06-09 153443.png" class="center">

<p>
So you see you essentially have two components: a drift component
and a variance component. 
</p>

<p>
In this new generalized process you have the following
characteristics:
</p>

<img src="../../images/Screenshot 2023-06-09 153648.png" class="center">
</div>
</div>


<div id="outline-container-org64e7157" class="outline-4">
<h4 id="org64e7157">Ito Process</h4>
<div class="outline-text-4" id="text-org64e7157">
<p>
Finally you have the Ito process that adds the condition that the
drift parameter <code>a</code> and the variance parameter <code>b</code> can be a
function of the underlying <code>x</code> and time <code>t</code>. They are not static
in this sense.
</p>

<img src="../../images/Screenshot 2023-06-09 154433.png" class="center">
</div>
</div>


<div id="outline-container-org6a76182" class="outline-4">
<h4 id="org6a76182">Ito's Lemma</h4>
<div class="outline-text-4" id="text-org6a76182">
<p>
Ito's Lemma state the following and how we will shortly see it is
the basis of arriving through the Black Scholes Formula that will
give a tool of analytically pricing some types of derivatives. 
</p>

<img src="../../images/Screenshot 2023-06-11 194724.png" class="center">

<p>
The Lemma is quite easy to prove. It consists simply of taking a
Taylor Expansion of the dG/dx. 
</p>

<p>
If you consider then the limit case dx -&gt; 0 and dt -&gt; 0 and ignore
higher terms in the Taylor expansion (cause they decay
sufficiently fast) you will get to the result.
</p>

<p>
The only part where you have to pay attention is the in the
following: <code>dx^2 = b^2 epsilon^2 * dt</code>. And therefore it is not
ignored. 
</p>

<p>
This is due to underlying ito process (and the fact that you
ignore higher order terms) where dx depends on the square root of
time as mentioned.
</p>
</div>
</div>

<div id="outline-container-org1cf1e12" class="outline-4">
<h4 id="org1cf1e12">Example of using Ito's Lemma</h4>
<div class="outline-text-4" id="text-org1cf1e12">
</div>
<ul class="org-ul">
<li><a id="org295f4e2"></a>Ito process for modeling Securities prices<br />
<div class="outline-text-5" id="text-org295f4e2">
<p>
The standard way you model a stock price is the following.
</p>

<p>
This is quite an intuitive process. You have a drift and variance
and both increase with the size of the investment.
</p>

<img src="../../images/Screenshot 2023-06-09 164514.png" class="center">

<p>
Note however that when taking the <b>expected returns</b> the parameters
of Ito's process are ultimately not more dependent on the stock
level itself.
</p>

<img src="../../images/Screenshot 2023-06-09 164613.png" class="center">
</div>
</li>

<li><a id="orgf6276fc"></a>Forward<br />
<div class="outline-text-5" id="text-orgf6276fc">
<p>
If you leverage Ito's lemma for pricing the forward you have:
</p>

<img src="../../images/Screenshot 2023-06-09 165159.png" class="center">
</div>
</li>

<li><a id="org253c4c3"></a>LogNoraml<br />
<div class="outline-text-5" id="text-org253c4c3">
<img src="../../images/Screenshot 2023-06-09 165255.png" class="center">

<img src="../../images/Screenshot 2023-06-09 165325.png" class="center">
</div>
</li>
</ul>
</div>

<div id="outline-container-org0b5145b" class="outline-4">
<h4 id="org0b5145b">Black Scholes</h4>
<div class="outline-text-4" id="text-org0b5145b">
<p>
Black Scholes is then nothing else of an application of the above.
</p>

<p>
The idea is basically the one of creating a risk neutral portfolio
given a stock and a derivative on that security.
</p>

<p>
From Ito's lemma we know that the underlying uncertainty is the
same in the stock and in the derivative. 
</p>

<p>
Than given that the underlying uncertainty is the same we can
construct a risk-free portfolio that should earn the risk free
rate in infinitesimal amount of time.
</p>

<p>
This is what we are going to do next and the result will be the
Black-Scholes solution for pricing derivatives on stocks.
</p>

<img src="../../images/Screenshot 2023-06-11 193210.png" class="center">

<img src="../../images/Screenshot 2023-06-11 193337.png" class="center">

<img src="../../images/Screenshot 2023-06-11 193427.png" class="center">
</div>
</div>
</div>


<div id="outline-container-org98c5694" class="outline-2">
<h2 id="org98c5694">Questions</h2>
<div class="outline-text-2" id="text-org98c5694">
</div>
<div id="outline-container-orgb75fe69" class="outline-3">
<h3 id="orgb75fe69">Risk Measures</h3>
<div class="outline-text-3" id="text-orgb75fe69">
</div>
<div id="outline-container-org8169a63" class="outline-4">
<h4 id="org8169a63">VaR</h4>
<div class="outline-text-4" id="text-org8169a63">
<ol class="org-ol">
<li><p>
What is Value at Risk:
</p>

<p>
Value at Risk is defined as the percentile of a return
 distribution.
</p>

<p>
In the 95%-VaR you would compute the maximum loss you would get
 in 95% of the cases given the return distribution.
</p>

<p>
VaR can be calculated in two ways:
</p>

<ol class="org-ol">
<li>using the historic return distribution. you would then compute
the 5% quantile based on such historic return distribution.</li>

<li>using a parameteric approach. You would define a parametric
distribution for the returns. You would then compute the
percentile of interest of it. If loss is normally distributed
then you know that it is the usual formula. You can also use
some more fancy solutions such as Cornish-Fisher Approximation
where you do a tailor expansion.</li>
</ol></li>

<li>What is wrong with VaR:

<ol class="org-ol">
<li>It does not take into account what happens in the tails after the
VaR quantile. For instance a distribution might have a big event
in there and another not. Both same VaR but obviously one is more
risky than the other.</li>

<li><p>
It does not satisfy the sub-additivity property of <b>coherent
risk measures</b>.
</p>

<p>
The sub-additivity property says that a risk measure p it
must hold
</p>

<pre class="example">
p (X) + p (Y) &gt;= p (X + Y)
</pre>

<p>
I.e. it ensures that merging positions decreases the risk.
</p>

<p>
This is not guaranteed by the VaR. So that aggregating risk
does not reduce risk. On the contrary <b>risk might be reduced
by splitting positions</b>.
</p>

<p>
I.e. even if all of your LOB satisfy VaR capital requirements,
your overall business does not.
</p></li>
</ol></li>
</ol>


<ol class="org-ol">
<li><p>
What is <b>non-linear VaR</b>:
</p>

<p>
 <b>Here the idea is essentially that the loss does not react
in a linear way to movements of the underlying</b>.
</p>

<p>
 This often comes in the case of derivatives, where you have
non-linearity in movements such as price etc. See <b>the
greeks</b> in this sense.
</p>

<p>
 The nonlinearity of certain derivatives leads to nonlinear
risk exposures in the VaR of a portfolio.
</p>

<p>
 Nonlinearity can be witnessed in the payoff diagram of a
plain vanilla call option. The payoff diagram has a strong
positive convex payoff profile before the option's expiration
date, with respect to the stock price.
</p>

<p>
 When the call option reaches a point where the option is in
the money, it reaches a point where the payoff becomes
linear. Conversely, as a call option becomes increasingly out
of the money, the rate at which the option loses money
decreases until the option premium is zero.
</p>

<blockquote>
<p>
Given such complex dynamics it makes sense to calulate the
VaR using Monte Carlo VaR simulations of options pricing
models to estimate the VaR of the portfolio.
</p>
</blockquote>

<ol class="org-ol">
<li><p>
Challenges of calculating VaR for a <b>mixed portfolio</b>?
</p>

<p>
The model becomes complex as there are potentially tons of
factors affecting each other. Very different <i>channels of
transmission</i>.
</p>

<p>
We might well have models to address risk of a particular
security/markets. However when having mixed portfolios it
becomes difficult to calculate the VaR for the global
portfolio.
</p>

<p>
This especially because the sub-additivity property is not
satisfied.
</p>

<blockquote>
<p>
GVAR (Global Vector AutoRegressive) methodology provides a
general, yet practical, global modelling framework for the
quantitative analysis of the relative importance of
different shocks and channels of transmission mechanisms.
</p>
</blockquote>

<p>
The individual country models are linked in a consistent manner
so that the GVAR model is solved for the world as a whole.
</p></li>
</ol>
<ol class="org-ol">
<li><p>
What is the one-day VaR of a $50m portfolio with a daily
standard deviation of 2% at a 95% confidence level?
</p>

<p>
The daily so it is:
</p>

<p>
VaR = 50M * 2* 0.02 = 2 Mio.
</p>

<p>
What is the annualized VaR?
</p>

<p>
Here there is time aggregation. You would need a <b>Loss
distribution model</b> for that time horizon. If you assume
i.i.d. returns then you can compute the annualized VaR as:
</p>

<blockquote>
<p>
VaR (1-day) + sqrt (365) = VaR (1-year)
</p>
</blockquote></li>
</ol></li>
</ol>
</div>
</div>

<div id="outline-container-org88ab31d" class="outline-4">
<h4 id="org88ab31d">Extreme Value Theory</h4>
<div class="outline-text-4" id="text-org88ab31d">
<ol class="org-ol">
<li><p>
What do you know about extreme value theory:
</p>

<p>
In extreme value theory you try to model the tails of the
distribution.
</p>

<p>
The issue is that for extreme events we have just a few
observations. Moreover such events there is non-stationarity
in the series. It is therefore impossible to treat them via
<b>times series techniques</b>.
</p>

<p>
The idea is then to abandon times series modeling.
</p>

<p>
The idea is to say.. you have realizations with distribution
F.
</p>

<p>
Then you ask what is the relation between the maximum among a
series X<sub>1</sub>, &#x2026;, X<sub>n</sub> and the tails of the distribution of F?
</p>

<p>
Then the idea is to get a sequence of maximum losses M<sub>n</sub> as
defined above, normalize this and check if it converges in
distribution to some distribution function H (X).
</p>

<p>
Then the idea is to create such sequences of maximum losses
from the data and estimate some extreme value distribution to
which it converges to. You also have to estimate the
normalizing factors. You then have an estimate for the
functional form of the tails (heavy tails).
</p>

<p>
Then there techniques to estimate the parameters of such
extreme value distributions. See for instance Hill-estimator
and Peak over Threshold.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-org7f4908e" class="outline-4">
<h4 id="org7f4908e">Expected Shortfall</h4>
<div class="outline-text-4" id="text-org7f4908e">
<ol class="org-ol">
<li><p>
What is Expected Shortfall?
</p>

<p>
It is the tail loss expectation. I.e. the expectation of
losses over the VaR loss.
</p>

<p>
<i>If things go bad - how bad can they get?</i>
</p></li>

<li><p>
Why is it considered better than VaR?
</p>

<p>
It addresses the two pitfalls above. I.e. does take into
account the entire tail. And is not blind from a threshold on
so to say.
</p>

<p>
Moreover it fulfills sub-additivity.
</p>

<p>
Moreover it is an <b>average</b>. CLT and LLN apply.
</p></li>

<li><p>
Disadvantages of ES?
</p>

<p>
<b>Backtesting more difficult</b>.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-orgc661c78" class="outline-4">
<h4 id="orgc661c78">Incremental Default Risk</h4>
<div class="outline-text-4" id="text-orgc661c78">
<p>
Default risk <b>incremental to what is calculated through the
Value-at-risk model</b>, which often does not adequately capture the
risk associated with illiquid products.
</p>
</div>
</div>


<div id="outline-container-org2768732" class="outline-4">
<h4 id="org2768732">Risk Neutrality and Pricing of Securities</h4>
<div class="outline-text-4" id="text-org2768732">
<p>
Here the entire idea is that if you have a set of n-linear
independent markets payoff for n-state, then you can create a risk
free security out of it.
</p>

<p>
If you have a risk free security you know that its return must be
the risk-free rate.
</p>

<p>
Then you know that you should not be able to earn more than the
risk-free rate on it.
</p>

<p>
Then you can price any security according to such schema.
</p>

<p>
Arrow-Debreu price -&gt; payoff 1 in one state 0 in all others.
</p>

<p>
Then with Arrow-Debreu prices you can get to the risk-neutral
expected payoff and price pay-off according to the risk-free rate.
</p>
</div>
</div>
</div>


<div id="outline-container-org0688faa" class="outline-3">
<h3 id="org0688faa">Yield Curve</h3>
<div class="outline-text-3" id="text-org0688faa">
<ul class="org-ul">
<li><p>
What is the discount factor? How would you calculate it?
</p>

<p>
Discount factor is the 1/ (1 + r) factor per period through which
you convert the future cash flow into Present Value cash flows.
</p>

<p>
How do you calculate it?
</p>

<p>
From the Bond price. You have an equation with known cash flows
and known price. Solve for the unkown variable.
</p>

<p>
This consists of risk-free rate plus risk-specific risk premium
of a particular stock.
</p>

<p>
You can then subtract the risk free rate from the treasury yield
curve to obtain the risk premium.
</p></li>

<li><p>
What is the riskiest part of the yield curve?
</p>

<p>
Under normal yield curve - the longer the horizon the riskier the
estimate is.
</p>

<p>
Even short deviations of interest rates have a huge impact on the
price on the net-present value of zero bond such that you will
have a huge impact on spot rate determined from these.
</p></li>

<li><p>
What does it mean for risk when the yield curve is inverted?
</p>

<p>
The relation of spot rates r<sub>t</sub> to their respective maturities t
is called the term structure of interest rates.
</p>

<p>
Spot Rate=(Face Value/Current Bond Price)<sup>(1/Years To Maturity)</sup>−1
</p></li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-16_um_14.13.40.png" class="center">

<p>
Inverted yield curve means that future cash flow are less
discounted than interest rates obtained in the next recent
period.
</p>

<p>
This means that the risk and liquidity premium for cash flows
obtained in recent period is higher than the one of the future.
</p>

<p>
This is seen as a precursor of an economic recession.
</p>

<p>
As a practical matter, recessions usually cause interest rates to
fall.
</p>

<ul class="org-ul">
<li><p>
What is duration?
</p>

<p>
The duration as a relative risk measure characterizes the
relative change of the bond price due to an absolute <b>parallel
shift</b> in the spot curve.
</p>

<p>
First derivative of bond price with respect to interest rate.
</p></li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-16_um_14.42.32.png" class="center">

<p>
In the case of non-flat term structure. I.e. when you work with
the spot rate:
</p>

<img src="../../images/Bildschirmfoto_2021-05-16_um_14.43.52.png" class="center">


<p>
The duration of a bond portfolio is the <b>weighted sum of durations
of its components</b> (duration is linear).
</p>

<ul class="org-ul">
<li><p>
What is convexity? How would you calculate it? Why is it
important?
</p>

<p>
Second derivative of bond price w.r.t. interest rate.
</p>

<p>
As the bond price does not react linearly to interest rates
movements but in a convex way you correct for such convex
structure with convexity.
</p>

<p>
Duration + Convexity  = Taylor expansion of second order.
</p></li>

<li><p>
Relation between coupon rate and convexity.
</p>

<p>
The higher the coupon rate the lower convexity.
</p></li>

<li><p>
What's the meaning of partial duration?
</p>

<p>
I think this is key-rate duration.
</p></li>
</ul>
</div>
</div>


<div id="outline-container-orgd48de0b" class="outline-3">
<h3 id="orgd48de0b">Quantitative Concepts</h3>
<div class="outline-text-3" id="text-orgd48de0b">
<ul class="org-ul">
<li>assumptions behind Black Scholes?

<ol class="org-ol">
<li>stock follows a GBM with <b>constant</b> drift and volatility.</li>

<li>short selling is allowed</li>

<li>no market frictions - transaction costs, taxes, securities are
arbitrarily divisible etc.</li>

<li>No dividends</li>

<li>No arbitrage opportunities exist</li>

<li>Securities are traded continously</li>

<li>Risk free constant for all maturities</li>
</ol></li>
</ul>


<ul class="org-ul">
<li><p>
what are Greeks?
</p>

<p>
greeks are the partial derivative of the derivative price with
respect to the model parameters movements.
</p>

<ol class="org-ol">
<li><p>
Monte Carlo Methods
</p>

<p>
Estimate the price of derivatives by simulating underlying
price movements. Computing payoffs and discounting these
according to risk-free payoff.
</p></li>

<li><p>
Finite Difference Methods:
</p>

<p>
Numerical method for discretizing the fundamental PDE.
</p></li>

<li><p>
Analytical Methods:
</p>

<p>
For some derivative exists.
</p></li>
</ol>
<ul class="org-ul">
<li><p>
What do you know about jump processes?
</p>

<p>
These are stochastic processes that make different assumptions on
 the underlying price movements in comparison to the standard GBM
 process.
</p>

<p>
You add jumps parameters in the stochastic differential
equation. Jumps are modeled by a poisson process. etc.
</p></li>
</ul></li>
</ul>


<ul class="org-ul">
<li><p>
Should you use implied or historical volatility for estimating
future volatility?
</p>

<p>
I would generally go with implied volatility. I would however
first be sure that the market is liquid and there are no supply
or demand imbalances driven by short term events.
</p>

<p>
See for instance the below:
</p>

<p>
The level of supply and demand, which drives implied volatility
metrics, can be affected by a variety of factors ranging from
market-wide events to news related directly to a single
company. For example, if several Wall Street analysts make
forecasts three days before a quarterly earnings report that a
company will soundly beat expected earnings, implied volatility
and options premiums could increase substantially in the few
days preceding the report. Once the earnings are reported,
implied volatility is likely to decline in the absence of a
subsequent event to drive demand and volatility.
</p></li>
</ul>
</div>
</div>


<div id="outline-container-orgb660b81" class="outline-3">
<h3 id="orgb660b81">Hedging</h3>
<div class="outline-text-3" id="text-orgb660b81">
<ul class="org-ul">
<li><p>
An option is at the money. How many shares of stock should you
hold to hedge it?
</p>

<p>
Generally speaking, an at-the-money option usually has a delta at
approximately 0.5 or -0.5. Measures the impact of a change in
volatility.
</p>

<p>
This is just a rough approximation as there the option price
change with respect to the fundamental is particularly convex.
</p></li>
</ul>


<ul class="org-ul">
<li><p>
What is volatility smile?
</p>

<p>
The idea is that volatility is an input variable for the
BS-formula.
</p>

<p>
Implied volatility is the volatility such that the option price
meets the actual observed market price.
</p>

<p>
Volatility smile shows how the implied volatility changes with
strike price.
</p>

<p>
As there is no closed form solution for solving for the implied
volatility you must use numerical methods to invert such
function.
</p></li>

<li><p>
when does hedging increase the risk?
</p>

<p>
PREFERRED answer:
</p>

<p>
If you just delta hedge you might end up with higher risk related
to the other <b>greek letters</b>.
</p>

<p>
Moreover note that delta hedging implies a buy high sell low
trading rule.
</p>

<p>
Moreover because of many model assumptions such as instantaneous
movements, local measures and model risk your hedge might in
general increase the risk.
</p>

<p>
OUTDATED:
</p>

<p>
Hedging can increase your risk if you are forced to both buy
short-dated options and hedge them.
</p>

<p>
idea then your option might exipire and you cannot sell or
realize profit as the price did not change too much to go out of
money.
</p></li>

<li><p>
How would you hedge against a particular equity/bond under
current market conditions?
</p>

<p>
You can delta hedge the risk.
</p></li>
</ul>
</div>
</div>


<div id="outline-container-org6ca8b65" class="outline-3">
<h3 id="org6ca8b65">Products</h3>
<div class="outline-text-3" id="text-org6ca8b65">
<ul class="org-ul">
<li><p>
What is interest rate risk? What is reinvestment risk?
</p>

<p>
For investors an increase in <b>interest rates</b> has <b>two effects</b>.
</p>

<ol class="org-ol">
<li>Prices of existing bonds drop in value (<b>interest rate risk</b>,
<b>price risk</b>)</li>

<li>received coupons can be invested at higher
rates. (<b>reinvestment risk</b>)</li>
</ol>

<p>
If investment horizon matches the duration both effects <b>offset
each other</b>.
</p></li>

<li><p>
Which bond has the greatest associated interest rate risk? A
five year zero coupon bond? Or a five year bond that pays
coupons?
</p>

<p>
a zero coupon bond. there all of the cash flow concentrated in
long-horizon so that given movements in interest rates more
affected due to higher discounting.
</p></li>

<li><p>
Which is more volatile, a 20-year zero coupon bond or a 20-year
4.5% coupon bond?
</p>

<p>
Answer 20-year zero coupon.
</p></li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-16_um_14.05.11.png" class="center">

<img src="../../images/Bildschirmfoto_2021-05-16_um_14.06.19.png" class="center">

<ul class="org-ul">
<li><p>
You have two options with the same underlying strike price. One
has an exercise date in three months, one has an exercise date
in six months. Which comes with the greatest risk?
</p>

<p>
The one six months. More uncertainty about the end-resulting
price. More volatility.
</p></li>
</ul>


<ul class="org-ul">
<li><p>
What’s the maximum potential loss you could incur by selling a
put on a stock?
</p>

<p>
The strike price -  price of selling option (that was your
payoff).
</p></li>

<li>What are the risks inherent in an interest rate swap?</li>

<li><p>
A stock is selling at $90. A 3-month call with a strike price of
$100 is selling for $3.105 with a delta of 0.329. How many call
contracts are required to perform a hedge on 1,000 shares of
this stock? Would they be bought or sold? What happens if the
price of the stock falls to $50?
</p>

<p>
Delta hedge = 1000 * 0.329
</p>

<p>
It is call option. In order to hedge it means I have to have the
opposite payoff. So if market goes up I have to have negative
payoff. It means you have to sell.
</p>

<p>
What happens if the price of the stock falls to $50?
</p>

<p>
You are once more not fully hedged. This because there is
convexity and the price movement was too big.
</p></li>
</ul>
</div>

<div id="outline-container-orgbaed213" class="outline-4">
<h4 id="orgbaed213">TODO</h4>
<div class="outline-text-4" id="text-orgbaed213">
<ul class="org-ul">
<li><p>
What are the risks inherent in an interest rate swap?
</p>

<p>
It depends in which position are you. If you are selling the
fixed component in exchange for the variable one you suffer from
declining interest rates and vice versa.
</p></li>

<li><p>
How would you decide which discount curve to use to value future
cash flows from interest rate swaps?
</p>

<p>
Two valuations possibilities.
</p>

<ol class="org-ol">
<li>swap as a difference between two bonds</li>

<li>as a set of forward rate agreements.</li>
</ol></li>
</ul>


<p>
Regarding 1. V<sub>swap</sub> = B<sub>fl</sub> - B<sub>fix</sub>. At the next accrual period
the B<sub>fl</sub> will be valued at it's principal amount. So just
compute the difference until accrual.
</p>
</div>
</div>
</div>


<div id="outline-container-org5716ae0" class="outline-3">
<h3 id="org5716ae0">Regulation</h3>
<div class="outline-text-3" id="text-org5716ae0">
<ul class="org-ul">
<li>Which extreme events should stress tests be taking into
consideration now?</li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-16_um_16.56.16.png" class="center">


<p>
Given such variables I would say:
</p>

<ol class="org-ol">
<li>Interest rates (see effect of starting doubts on rising
inflation and effect on prices)</li>

<li>Equity markets - especially tech markets. Some people claim
these are vastly overvalued.</li>

<li>GDP and Unemployment - due to covid</li>

<li>Plus debt markets - very special situation due to Covid. Lots of
liquidity in the market. Huge debt of Governments.</li>

<li>Why is Basel II blamed for precipitating the 2008 financial
crisis?</li>
</ol>

<img src="../../images/Bildschirmfoto_2021-05-16_um_19.32.06.png" class="center">


<p>
The 2008 financial crisis revealed a major gap in the inability to
adequately identify the credit risk of the trading book positions
</p>

<ul class="org-ul">
<li><p>
How has Babel III changed the treatment of market risk?
</p>

<p>
There was the introduction of liquidity ratios and another
liquidity factor..
</p>

<p>
Introduced internationally consistent liquidity standards, a
leverage constraint, and a floor requirement applied to
risk‐weighted assets (RWAs).
</p>

<p>
To limit <b>procyclicality</b> macro-prudential regulation.
</p></li>

<li><p>
What the implications of Basel IIIs new trading book rules for
market risk professionals?
</p>

<p>
they will likely have to price in the higher cost of capital for
increased book.. don't know exactly the answer.. would need to
collect some more practical experience on the field to answer
such questions.
</p></li>

<li><p>
How could the Basel III treatment of trading books be improved?
</p>

<p>
don't have enough domain knowledge in that.
</p></li>

<li><p>
How will trading businesses change as a result of Basel III
capital rules for banks’ trading books?
</p>

<p>
not have enough domain knowledge in this.
</p></li>

<li><p>
Changes in Basel III
</p>

<p>
Banks no longer have the option to use the advanced IRB approach
for certain asset classes. The advanced IRB approach allows banks
to estimate PD and EAD in certain scenarios, particularly when
there are insufficient data to model an exposure in precise
terms. Instead, they are now required to use the Foundation IRB
approach which introduces fixed values for the LGD and EAD.
</p></li>
</ul>


<ul class="org-ul">
<li>A lot of talking about this fundamental review of trading book</li>
</ul>

<img src="../../images/Bildschirmfoto_2021-05-17_um_10.29.34.png" class="center">

<p>
Will come into action in the coming years. Major thing is the
change from VaR to Expected Shortfall.
</p>
</div>
</div>


<div id="outline-container-orgbea555a" class="outline-3">
<h3 id="orgbea555a">Stress testing life cycle</h3>
<div class="outline-text-3" id="text-orgbea555a">
<img src="../../images/Bildschirmfoto_2021-05-17_um_08.37.28.png" class="center">
</div>
</div>
</div>
