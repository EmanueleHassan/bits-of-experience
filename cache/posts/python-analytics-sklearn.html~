<p>
This is a repository where I hold some notes about the major sklearn
analytics algorithm in order to perform your data science. 
</p>


<!-- TEASER_END -->


<div id="outline-container-org0941dbc" class="outline-2">
<h2 id="org0941dbc">General Pattern</h2>
<div class="outline-text-2" id="text-org0941dbc">
<p>
The standard way of working with your data is first performing the
relevant exploratory data.
</p>

<p>
For it you can refer to the relevant separate post.
</p>

<p>
There you would inspect the data both analytically as well as
visually.
</p>

<p>
The goal is to understand what is available in the data.
</p>

<p>
The distribution of the data etc. 
</p>

<p>
In such a way it would be possible for you to create the relevant
features from the data. 
</p>

<p>
When creating the features it will be important to <b>transform</b> the
data such that they take a meaningful shape. You might need to
one-hot-encode, standardize, impute etc.  Note that you might fit
data as well in order to get to the transform the data
accordingly. In this sense, you will find a <code>fit_transform</code> API in
sklearn.
</p>

<p>
After the data have been properly transformed it is time to fit the
actual analytical model. Here you would take one of the relevant <b>supervised</b> /
<b>unsupervised</b> models and you would ultimately fit them to the
main chunck of the data. 
</p>

<p>
Finally, you would estimate / predict a new existing chunck of the
data given your fitted model and its parameters.
</p>
</div>


<div id="outline-container-org4a5f9f8" class="outline-3">
<h3 id="org4a5f9f8">Fit</h3>
</div>




<div id="outline-container-org508160c" class="outline-3">
<h3 id="org508160c">Transform</h3>
<div class="outline-text-3" id="text-org508160c">
<p>
Here are mentioned some of the classical techniques for tranforming
your data in order to make them meaningful / well behaved.
</p>
</div>


<div id="outline-container-orga59313d" class="outline-4">
<h4 id="orga59313d">The preprocessor object</h4>
<div class="outline-text-4" id="text-orga59313d">
<p>
In order to pre-process the data sklearn offers the preprocessor
object class.
</p>


<p>
There you have many different APIs that are useful in order to
process the data.
</p>

<p>
We will explore them next.
</p>
</div>

<ul class="org-ul">
<li><a id="org5f6be00"></a>Dataset<br />
<div class="outline-text-5" id="text-org5f6be00">
<p>
In this section I will work with the datasets shipped with the
sklearn package.
</p>

<p>
In order to use the data use the following:
</p>

<div class="highlight"><pre><span></span>     from sklearn.datasets import fetch_california_housing as fdh
     import pandas as pd
     import numpy as np
</pre></div>

<div class="highlight"><pre><span></span>     df_housing = fdh (as_frame=1) [&#39;data&#39;]

     df_housingValue = fdh (as_frame=1)[&#39;target&#39;]

     df_housing.head (5)
</pre></div>
</div>
</li>



<li><a id="org4d58946"></a>Binarizer<br />
<div class="outline-text-5" id="text-org4d58946">
<p>
This converts data into binary given a certain threshold. 
</p>

<p>
You could for instance create a future in the above for checking
whether the data are in the northern hemisphere or in the
southern one in the following way:
</p>

<div class="highlight"><pre><span></span>     from sklearn.preprocessing import Binarizer
</pre></div>

<div class="highlight"><pre><span></span>     binary = Binarizer () ## note that it holds a parameter threshold. The
			   ## default is 0 and is good for the exercise of
			   ## Northern and Southern Hemisphere.

     binary.fit (np.array (df_housing [&quot;Latitude&quot;]).reshape (-1,1)) ## Note
								    ## that
								    ## the
								    ## Binarizer
								    ## takes
								    ## a 2D
								    ## array
								    ## as
								    ## input. You
								    ## therefore
								    ## need
								    ## to
								    ## reshape
								    ## your
								    ## data
								    ## and
								    ## wrap
								    ## your
								    ## array
								    ## into
								    ## a
								    ## list.
</pre></div>


<div class="highlight"><pre><span></span>     df_housing [&quot;Northern Hemisphere&quot;] = binary.transform (np.array (df_housing [&quot;Latitude&quot;]).reshape (-1,1)).flatten () ## Flatten
															  ## out
															  ## back
															  ## to
															  ## a
															  ## 1D
															  ## array
</pre></div>


<div class="highlight"><pre><span></span>     df_housing.head (5)
</pre></div>



<p>
Note that you can specify the threshold yourself. Think about the
case of Housing age. You want to create a binary if older than
the age or not.
</p>

<p>
You can then use the following:
</p>

<div class="highlight"><pre><span></span>     df_housing [&quot;OldHouse&quot;] = Binarizer (threshold= df_housing.HouseAge.mean ()) \
			       .fit_transform (np.array (df_housing [&quot;HouseAge&quot;]).reshape (-1,1)).flatten ()
</pre></div>


<div class="highlight"><pre><span></span>     df_housing.head (10)
</pre></div>
</div>
</li>


<li><a id="org6bf2a2b"></a>QuantileTransformer<br />
<div class="outline-text-5" id="text-org6bf2a2b">
<p>
Note that this estimates the quantiles according to a parameteric
distribution that you impose on the data. 
</p>

<p>
It does not compute the quantiles based on the empirical
distribution of the data. Check in this sense the <code>qcut</code> method.
</p>

<p>
Note that this preprocessor function allows to estimate and fit
the quantiles of a uniform and normal distribution.
</p>

<div class="highlight"><pre><span></span>     from sklearn.preprocessing import QuantileTransformer
</pre></div>

<p>
So note that the exercise is different in comparison to the
quantile cut.
</p>

<p>
The idea is to compute <code>n_quantiles</code> quantiles from the actual
data. And then interpolate across them according to a
distribution of choice - be uniform or normal - in order to
compute the rest of the quantiles.
</p>
</div>


<ul class="org-ul">
<li><a id="org6bc989b"></a><span class="todo TODO">TODO</span> Plot histogram of the data<br />
<div class="outline-text-6" id="text-org6bc989b">
<div class="highlight"><pre><span></span>
</pre></div>
</div>
</li>


<li><a id="org444fab1"></a><span class="todo TODO">TODO</span> some transformation - plot the thing in order to it clear and double check that the thing is the one you have in mind.<br />
<div class="outline-text-6" id="text-org444fab1">
<div class="highlight"><pre><span></span>      QuantileTransformer(n_quantiles=5, random_state=0).fit_transform (np.array (df_housingValue).reshape (-1,1)).flatten ()
</pre></div>
</div>
</li>
</ul>
</li>


<li><a id="orga7e1452"></a>Standard Scaler<br /></li>



<li><a id="org61227e6"></a>MaxAbsScalerp<br /></li>



<li><a id="orgc5815a5"></a>LabelEncoder<br /></li>



<li><a id="org9a7436e"></a>OneHotEncoder<br /></li>



<li><a id="org3e03f6e"></a>KernelCenterer<br /></li>



<li><a id="org5937f6f"></a>FunctionTransformer<br /></li>



<li><a id="orgbfb684a"></a>FunctionTransformer<br /></li>
</ul>
</div>
</div>




<div id="outline-container-org32518ef" class="outline-3">
<h3 id="org32518ef">Predict</h3>
</div>


<div id="outline-container-orgcab4690" class="outline-3">
<h3 id="orgcab4690"><span class="todo TODO">TODO</span> create a different posts listing the different fitting metrics</h3>
</div>


<div id="outline-container-orgc755e1b" class="outline-3">
<h3 id="orgc755e1b"><span class="todo TODO">TODO</span> adjust the post on pipelines</h3>
<div class="outline-text-3" id="text-orgc755e1b">
<p>
Not 100% clear in its current form how that works. 
</p>
</div>
</div>
</div>

<div id="outline-container-org4a0f3c7" class="outline-2">
<h2 id="org4a0f3c7">Imputer</h2>
</div>




<div id="outline-container-org7cfe627" class="outline-2">
<h2 id="org7cfe627">Linear Regression</h2>
<div class="outline-text-2" id="text-org7cfe627">
</div>

<div id="outline-container-orgd537074" class="outline-3">
<h3 id="orgd537074">Data</h3>
<div class="outline-text-3" id="text-orgd537074">
<div class="highlight"><pre><span></span>   import pandas as pd
   import numpy as np
   from matplotlib import pyplot as plt

   # Generate &#39;random&#39; data
   np.random.seed(0)
   X = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5
   res = 0.5 * np.random.randn(100)       # Generate 100 residual terms
   y = 2 + 0.3 * X + res                  # Actual values of Y

   # Create pandas dataframe to store our X and y values
   df = pd.DataFrame(
       {&#39;X&#39;: X,
	&#39;y&#39;: y}
   )

   # Show the first five rows of our dataframe
   df.head()
</pre></div>
</div>
</div>


<div id="outline-container-org839923a" class="outline-3">
<h3 id="org839923a">Getting the Regression Coefficients Manually via Analytical Solution</h3>
<div class="outline-text-3" id="text-org839923a">
<p>
Get the relevant coefficients of the regression:
</p>

<div class="highlight"><pre><span></span>   # Calculate the mean of X and y
   xmean = np.mean(X)
   ymean = np.mean(y)

   # Calculate the terms needed for the numator and denominator of beta
   df[&#39;xycov&#39;] = (df[&#39;X&#39;] - xmean) * (df[&#39;y&#39;] - ymean)
   df[&#39;xvar&#39;] = (df[&#39;X&#39;] - xmean)**2

   # Calculate beta and alpha
   beta = df[&#39;xycov&#39;].sum() / df[&#39;xvar&#39;].sum()
   alpha = ymean - (beta * xmean)
   print(f&#39;alpha = {alpha}&#39;)
   print(f&#39;beta = {beta}&#39;)
</pre></div>


<div class="highlight"><pre><span></span>   ypred = alpha + beta * X
</pre></div>
</div>

<div id="outline-container-org871ef38" class="outline-4">
<h4 id="org871ef38">Matplotlib of regression</h4>
<div class="outline-text-4" id="text-org871ef38">
<p>
Plot the relevant results:
</p>

<div class="highlight"><pre><span></span>    import matplotlib.pyplot as plt
    %matplotlib inline 
    %config InlineBackend.figure_format = &#39;png&#39;
</pre></div>


<div class="highlight"><pre><span></span>    # Plot regression against actual data
    plt.figure(figsize=(12, 6))
    plt.plot(X, ypred)     # regression line
    plt.plot(X, y, &#39;ro&#39;)   # scatter plot showing actual data
    plt.title(&#39;Actual vs Predicted&#39;)
    plt.xlabel(&#39;X&#39;)
    plt.ylabel(&#39;y&#39;)

    plt.show()
</pre></div>

<img src="../../images/Regression.png" class="center">
</div>
</div>
</div>


<div id="outline-container-org3c724ac" class="outline-3">
<h3 id="org3c724ac">Model Fit and Prediction</h3>
<div class="outline-text-3" id="text-org3c724ac">
</div>
<div id="outline-container-org245418c" class="outline-4">
<h4 id="org245418c">The standard way to fit and predict in skit-learn</h4>
<div class="outline-text-4" id="text-org245418c">
<div class="highlight"><pre><span></span>    from sklearn.linear_model import LinearRegression

    # Initialise and fit model
    lm = LinearRegression()
    model = lm.fit(X.reshape(-1, 1), y)
</pre></div>


<div class="highlight"><pre><span></span>    print(f&#39;alpha = {model.intercept_}&#39;)
    print(f&#39;betas = {model.coef_}&#39;)
</pre></div>


<div class="highlight"><pre><span></span>    model.predict(X.reshape(-1, 1))
</pre></div>
</div>
</div>
</div>
</div>
